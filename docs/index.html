

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>&lt;no title&gt; &mdash; VoiceLab: Automated Reproducible Acoustic Analysis</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="#" class="icon icon-home"> VoiceLab
          

          
          </a>

          
            
            
              <div class="version">
                2.2.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <!-- Local TOC -->
              <div class="local-toc"><ul class="simple">
</ul>
</div>
            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">VoiceLab</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="#" class="icon icon-home"></a> &raquo;</li>
        
      <li>&lt;no title&gt;</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <p>% This Sphynx rst file depends on sphinxcontrib-inlinesyntaxhighlight</p>
<p># Voice Lab Interface</p>
<p><code class="docutils literal notranslate"><span class="pre">`{eval-rst}</span>
<span class="pre">..</span> <span class="pre">highlight::</span> <span class="pre">rst</span>
<span class="pre">`</span></code></p>
<p><a href="#id1"><span class="problematic" id="id2">``</span></a><a href="#id3"><span class="problematic" id="id4">`</span></a>{eval-rst}
.. role:: python(code)</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">language<span class="colon">:</span></dt>
<dd class="field-odd"><p>python</p>
</dd>
</dl>
</div></blockquote>
<p><a href="#id5"><span class="problematic" id="id6">``</span></a><a href="#id7"><span class="problematic" id="id8">`</span></a></p>
<p><a href="#id9"><span class="problematic" id="id10">``</span></a><a href="#id11"><span class="problematic" id="id12">`</span></a>{eval-rst}
.. toctree:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">:</span><span class="n">numbered</span><span class="p">:</span>
<span class="p">:</span><span class="n">maxdepth</span><span class="p">:</span> <span class="mi">2</span>
</pre></div>
</div>
<p><a href="#id13"><span class="problematic" id="id14">``</span></a><a href="#id15"><span class="problematic" id="id16">`</span></a></p>
<p>Voice Lab is an automated voice analysis software. What this software does is allow you to measure, manipulate, and visualize many voices at once, without messing with analysis parameters. You can also save all of your data, analysis parameters, manipulated voices, and full colour spectrograms with the press of one button.</p>
<p>Voice Lab is written in Python and relies heavily on a package called parselmouth-praat. parselmouth-praat is a Python package that essentially turns Praat’s source code written in C and C++ into a Pythonic interface. What that means is that any praat measurement in this software is using actual Praat source code, so you can trust the underlying algorithms. Voice Lab figures out all of the analysis parameters for you, but you can always use your own, and these are the same parameters as in Praat, and they do the exact same thing because it is Praat’s source code powering everything. That means if you are a beginner an expert, or anything in-between, you can use this software to automate your acoustical analyses.</p>
<p>All of the code is open source and available on our GitHub repository, so if this manual isn’t in-depth enough, and you want to see exactly what’s going on, go for it. It is under the MIT license, so you are free to do what you like with the software as long as you give us credit. For more info on that license, see here.</p>
<p>## Load Voices Tab</p>
<p><code class="docutils literal notranslate"><span class="pre">`{image}</span> <span class="pre">_static/LoadVoices.png</span>
<span class="pre">:alt:</span> <span class="pre">Load</span> <span class="pre">voices</span> <span class="pre">window</span>
<span class="pre">:width:</span> <span class="pre">400</span>
<span class="pre">`</span></code></p>
<p>### Load Sound File</p>
<p>Press this button to load sound files. You can load as many files as you like.
At the moment, Voice Lab processes the following file types:</p>
<ul class="simple">
<li><p>wav</p></li>
<li><p>mp3</p></li>
<li><p>aiff</p></li>
<li><p>ogg</p></li>
<li><p>aifc</p></li>
<li><p>au</p></li>
<li><p>nist</p></li>
<li><p>flac</p></li>
</ul>
<p>### Remove Sound File</p>
<p>Use this button to remove the selected sound file(s) from the list.</p>
<p>### Start</p>
<p>Pressing this begins analysis. If you want to run the default analysis, press this button.
If you want to select different analyses or adjust analysis parameters, go to the ‘Settings’ tab and press the ‘Advanced Settings’ button.
Only the files selected (in blue) will be analyzed. By default we will select all files.</p>
<p>(settings)=</p>
<p>## Settings Tab</p>
<p><code class="docutils literal notranslate"><span class="pre">`{image}</span> <span class="pre">_static/settings.png</span>
<span class="pre">:alt:</span> <span class="pre">Settings</span> <span class="pre">window</span>
<span class="pre">:width:</span> <span class="pre">400</span>
<span class="pre">`</span></code></p>
<p>To choose different analyses, select the {python}`Use Advanced Settings` checkbox. From here, you’ll be given the option to select different analyses. You can also change any analysis parameters. If you do change analysis parameters, make sure you know what you are doing, and remember that those same analysis parameters will be used on all voice files that are selected. If you don’t alter these parameters, we determine analysis parameters automatically for you, so they are tailored for each voice to give the best measurements.</p>
<p>### Save Results</p>
<p>Save Results saves two xlsx files. One is the results.xlsx file and one is the settings.xlsx file. Here you can choose the directory you want to save the files into. You don’t have to click on a file, just go to the directory and press the button.</p>
<p>#### results.xlsx</p>
<p>The results file saves all of the voice measurements that you made. Each measurement gets a separate tab in the xlsx file.</p>
<p>#### settings.xlsx</p>
<p>This file saves all of the parameters used in each measurement. Each measurement gets a separate tab in the xlsx file. This is great if you want to know what happened. It can also accompany a manuscript or paper to help others replicate analyses.</p>
<p>### Results Tab</p>
<p><code class="docutils literal notranslate"><span class="pre">`{image}</span> <span class="pre">_static/output_window.png</span>
<span class="pre">:alt:</span> <span class="pre">Results</span> <span class="pre">window</span>
<span class="pre">:width:</span> <span class="pre">400</span>
<span class="pre">`</span></code></p>
<p>This is where you can view results. You can select each voice file on the left and view each measurement result on the bottom frame. You can also view your spectrograms in the spectrogram window. You can change the size of any of these frames in order to see things better. Press {python}`Save Results` to save data. All data (results &amp; settings), manipulated voices, and spectrograms are saved automatically when this button is pressed. All you have to do is choose which folder to save into. Don’t worry about picking file names, Voice Lab will make those automatically for you.</p>
<p>#### Output formats</p>
<ul class="simple">
<li><p>All data files are saved as xlsx</p></li>
<li><p>All sound files are saved as wav</p></li>
<li><p>All image files are saved as png</p></li>
</ul>
<p># Documentation and API Reference</p>
<p>THe API is not a supported way to run Voicelab, but it works, with some elbow grease.
You need to clone the github repo and run it from the command line, but not if you install it from PyPi or Binary. You
can adapt this process for any node.  See source code for the node you want to run for more details. I have the
directory structure set up below in the code examples. It’s just at test file, but you can see how to make it work.
In short, The prepare_node() function sets up the node with the sound file the way it likes it and returns the node. The
process() method runs the node.</p>
<p>## Automated Settings</p>
<p>VoiceLab uses automated settings for pitch floor and ceiling, and also uses these to set the centre frequency parameter in the FormantPath formant analysis.</p>
<p>(floor-ceiling)=</p>
<p>### Automated pitch floor and ceiling parameters</p>
<p>Praat suggests adjusting pitch settings based on [gender](<a class="reference external" href="http://www.fon.hum.uva.nl/praat/manual/Intro_4_2__Configuring_the_pitch_contour.html">http://www.fon.hum.uva.nl/praat/manual/Intro_4_2__Configuring_the_pitch_contour.html</a>) . It’s not gender per se that is important, but the pitch of voice. To mitigate this, VoiceLab first casts a wide net in  floor and ceiling settings to learn the range of probable fundamental frequencies is a voice. Then it remeasures the voice pitch using different settings for higher and lower pitched voices. VoiceLab by default uses employs {python}`very accurate`. VoiceLab returns {python}`minimum pitch`, {python}`maximum pitch`, {python}`mean pitch`, and {python}`standard deviation of pitch`. By default VoiceLab uses  autocorrelation for {ref}`Measuring Pitch&lt;Pitch&gt;`, and cross-correlation for {ref}`harmonicity&lt;HNR&gt;`, {ref}`Jitter&lt;Jitter&gt;`, and {ref}`Shimmer&lt;Shimmer&gt;`,</p>
<p>## Measurement Nodes</p>
<p>(pitch)=</p>
<p>### Measure Pitch</p>
<p>This measures voice pitch or fundamental frequency. Users can measure pitch using any number of the following algorithms:
: - Praat Autocorrelation</p>
<blockquote>
<div><ul class="simple">
<li><p>Praat Cross Correlation</p></li>
<li><p>Yin (From Librosa)</p></li>
<li><p>Subharmonics (from Open Sauce)</p></li>
</ul>
</div></blockquote>
<p>By default it will measure all of these.</p>
<p>This uses Praat’s {python}`Sound: To Pitch (ac)…`, by default. You can also use the cross-correlation algorithm: {python}`Sound: To Pitch (cc)…`. For full details on these algorithms, see the [praat manual pitch page](<a class="reference external" href="http://www.fon.hum.uva.nl/praat/manual/Pitch.html">http://www.fon.hum.uva.nl/praat/manual/Pitch.html</a>).
{python}`Measure Pitch` returns the following measurements:</p>
<p>&gt; - A list of the pitch values
&gt; - Minimum Pitch
&gt; - Maximum Pitch
&gt; - Mean Pitch
&gt; - Standard Deviation of Pitch
&gt; - Pitch Floor (used to set window length)
&gt; - Pitch Ceiling (no candidates above this value will be considered)</p>
<p>We use the automated pitch floor and ceiling parameters described {ref}`here.&lt;floor-ceiling&gt;`</p>
<p>#### Measure Pitch Yin</p>
<p>This is the Yin implementation from Librosa.  This is now run out of the Measure Pitch Node.</p>
<p><a href="#id17"><span class="problematic" id="id18">``</span></a><a href="#id19"><span class="problematic" id="id20">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasurePitchNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id21"><span class="problematic" id="id22">``</span></a><a href="#id23"><span class="problematic" id="id24">`</span></a></p>
<p>#### Measure Subharmonics</p>
<p>This measures subharmonic pitch and subharmonic to harmonic ratio. Subharmonic to harmonic ratio and Subharmonic pitch are measures from Open Sauce (Yu et al., 2019), a Python port of Voice Sauce (Shue et al., 2011).  These measurements do not use any Praat or Parselmouth code.  As in (Shue et al., 2011) and (Yu et al., 2019), subharmonic raw values are padded with NaN values to 201 data points.</p>
<p><a href="#id25"><span class="problematic" id="id26">``</span></a><a href="#id27"><span class="problematic" id="id28">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureSHRPNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id29"><span class="problematic" id="id30">``</span></a><a href="#id31"><span class="problematic" id="id32">`</span></a></p>
<p>(cpp)=</p>
<p>### Measure CPP (Cepstral Peak Prominence)</p>
<p>This measures Cepstral Peak Prominance in Praat. You can adjust interpolation, qeufrency upper and lower bounds, line type, and fit method.</p>
<p><a href="#id33"><span class="problematic" id="id34">``</span></a><a href="#id35"><span class="problematic" id="id36">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureCPPNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id37"><span class="problematic" id="id38">``</span></a><a href="#id39"><span class="problematic" id="id40">`</span></a></p>
<p>(duration)=</p>
<p>### Measure Duration</p>
<p>This measures the full duration of the sound file. There are no parameters to adjust.</p>
<p>(energy)=</p>
<p>### Measure Energy</p>
<p>This is my port of VoiceSauce’s Energy Algorithm.  It is different than the old RMS Energy algorithm in previous
versions of VoiceLab, which was RMS of the file and is still available. This code is not in OpenSauce. It is a line-by
line translation of the Voice Sauce MatLab and Praat Code.  Validation analyses for automatic analysis settings and
Energy can be found [here&lt;<a class="reference external" href="https://osf.io/3wr6k/files/">https://osf.io/3wr6k/files/</a>&gt;][here&lt;<a class="reference external" href="https://osf.io/3wr6k/files/">https://osf.io/3wr6k/files/</a>&gt;].</p>
<p>It is a normal Energy calculation, but the widow size is equal to 5 pitch periods, estimated by my port of Voice
Sauce’s Praat script to Python using the praat-parselmouth package.</p>
<p><a href="#id41"><span class="problematic" id="id42">``</span></a><a href="#id43"><span class="problematic" id="id44">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureEnergyNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id45"><span class="problematic" id="id46">``</span></a><a href="#id47"><span class="problematic" id="id48">`</span></a></p>
<p>(formants)=</p>
<p>### Measure Formants</p>
<p>This returns the mean of the first 4 formant frequencies of the voice using the {python}`To FormantPath` algorithm using
5.5 maximum number of formants and a variable centre frequency, set automatically or user-specified.  All other values
are Praat defaults for Formant Path.  Formant path picks the best formant ceiling value by fitting each prediction to a
polynomial curve, and choosing the best fit for each formant. The centre frequency is determined in the automatic
settings You can also use your own settings for {python}`To Formant Burg…` if you want to.</p>
<p><a href="#id49"><span class="problematic" id="id50">``</span></a><a href="#id51"><span class="problematic" id="id52">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureFormantNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id53"><span class="problematic" id="id54">``</span></a><a href="#id55"><span class="problematic" id="id56">`</span></a></p>
<p>### Measure Vocal Tract Length Estimates</p>
<p>This returns the following vocal tract length estimates:</p>
<p>#### Average Formant</p>
<p>This calculates the mean $frac {sum _{i=1}^{n} {f_i}}{n}$ of the first four formant frequencies for each sound.</p>
<p>Pisanski, K., &amp; Rendall, D. (2011). The prioritization of voice fundamental frequency or formants in listeners’ assessments of speaker size, masculinity, and attractiveness. The Journal of the Acoustical Society of America, 129(4), 2201-2212.</p>
<p>#### Principle Components Analysis</p>
<p>This returns the first factor from a Principle Components Analysis (PCA) of the 4 formants.</p>
<p>Babel, M., McGuire, G., &amp; King, J. (2014). Towards a more nuanced view of vocal attractiveness. PloS one, 9(2), e88616.</p>
<p>#### Geometric Mean</p>
<p>This calculates the geometric mean $left(prod _{i=1}^{n}f_{i}right)^{frac {1}{n}}$ of the first 4 formant frequencies for each sound.</p>
<p>Smith, D. R., &amp; Patterson, R. D. (2005). The interaction of glottal-pulse rate andvocal-tract length in judgements of speaker size, sex, and age.Journal of theAcoustical Society of America, 118, 3177e3186.</p>
<p>#### Formant Dispersion</p>
<p>$frac {sum _{i=2}^{n} {f_i - f_{i-1}}}{n}$</p>
<p>Fitch, W. T. (1997). Vocal-tract length and formant frequency dispersion correlate with body size in rhesus macaques.Journal of the Acoustical Society of America,102,1213e1222.</p>
<p>#### VTL</p>
<p>$frac {sum _{i=1}^{n} (2n-1) frac {f_i}{4c}}{n}$</p>
<p>Fitch, W. T. (1997). Vocal-tract length and formant frequency dispersion correlate with body size in rhesus macaques.Journal of the Acoustical Society of America,102,1213e1222.</p>
<p>Titze, I. R. (1994).Principles of voice production. Englewood Cliffs, NJ: Prentice Hall.</p>
<p>#### VTL Δf</p>
<p>$f_i$ = The slope of 0 intercept regression between $F_i = frac {(2i-1)}{2} Δf$ and the mean of each of the first 4 formant frequencies.</p>
<p>$VTL f_i = frac {sum _{i=1}^{n} (2n-1)(frac {c}{4f_i})}{n}$</p>
<p>$VTL Delta f = frac {c}{2Δf}$</p>
<p>Reby,D.,&amp;McComb,K.(2003).Anatomical constraints generate honesty: acoustic cues to age and weight in the roars of red deer stags. Animal Behaviour, 65,519e530.</p>
<p>(formant-position)=</p>
<p>#### Measure Formant Positions Node</p>
<p>This node measures formant position. This node is executed by MeasureVocalTractEstimatesNode.</p>
<p>Formant Position is set to only run on samples of 30 or greater because this measure is based on scaling the data. Without a large enough sample, this measurement could be suspicious.</p>
<p>The algorithm is as follows:
: - First, measure formants at each gottal pulse.</p>
<blockquote>
<div><ul>
<li><p>Second, scale each formant separately.</p></li>
<li><p>Third, find the mean of the scaled formants.</p>
<p>&gt; - $frac{1}{n} {sum _{i=1}^{n}{f_i}}$</p>
</li>
</ul>
</div></blockquote>
<p>This algorithm deviates from the original in that it checks the data for a normal distribution before applying the z-score. If it is not normally distributed, it uses Scikit Learn’s [Robust Scalar](<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html">https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html</a>)
The scalar method is recorded in the voicelab_settings.xlsx file.</p>
<p>Puts, D. A., Apicella, C. L., &amp; Cárdenas, R. A. (2011). Masculine voices signal men’s threat potential in forager and industrial societies. Proceedings of the Royal Society B: Biological Sciences, 279(1728), 601-609.</p>
<p><a href="#id57"><span class="problematic" id="id58">``</span></a><a href="#id59"><span class="problematic" id="id60">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureVocalTractEstimatesNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id61"><span class="problematic" id="id62">``</span></a><a href="#id63"><span class="problematic" id="id64">`</span></a></p>
<p><a href="#id65"><span class="problematic" id="id66">``</span></a><a href="#id67"><span class="problematic" id="id68">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureFormantPositionsNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id69"><span class="problematic" id="id70">``</span></a><a href="#id71"><span class="problematic" id="id72">`</span></a></p>
<p>(hnr)=</p>
<p>### Measure Harmonicity</p>
<p>This measures mean harmonics-to-noise-ratio using automatic floor and ceiling settings described {ref}`here.&lt;floor-ceiling&gt;`  Full details of the algorithm can be found in the [Praat Manual Harmonicity Page&lt;<a class="reference external" href="http://www.fon.hum.uva.nl/praat/manual/Harmonicity.html">http://www.fon.hum.uva.nl/praat/manual/Harmonicity.html</a>&gt;][praat manual harmonicity page&lt;<a class="reference external" href="http://www.fon.hum.uva.nl/praat/manual/harmonicity.html">http://www.fon.hum.uva.nl/praat/manual/harmonicity.html</a>&gt;]. By default Voice Lab use {python}`To Harmonicity (cc)..`. You can select {python}`To Harmonicity (ac)` or change any other Praat parameters if you wish.</p>
<p><a href="#id73"><span class="problematic" id="id74">``</span></a><a href="#id75"><span class="problematic" id="id76">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureHarmonicityNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id77"><span class="problematic" id="id78">``</span></a><a href="#id79"><span class="problematic" id="id80">`</span></a></p>
<p>### Measure Intensity</p>
<p>This returns the mean of Praat’s  {python}`Sound: To Intensity…` function in dB. You can adjust the minimum pitch parameter. For more information, see Praat
s [Configuring the intensity contour Page](<a class="reference external" href="https://www.fon.hum.uva.nl/praat/manual/Intro_6_2__Configuring_the_intensity_contour.html">https://www.fon.hum.uva.nl/praat/manual/Intro_6_2__Configuring_the_intensity_contour.html</a>).</p>
<p><a href="#id81"><span class="problematic" id="id82">``</span></a><a href="#id83"><span class="problematic" id="id84">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureIntensityNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id85"><span class="problematic" id="id86">``</span></a><a href="#id87"><span class="problematic" id="id88">`</span></a></p>
<p>(jitter)=</p>
<p>### Measure Jitter</p>
<p>This measures and returns values of all of [Praat’s jitter algorithms](<a class="reference external" href="http://www.fon.hum.uva.nl/praat/manual/Voice_2__Jitter.html">http://www.fon.hum.uva.nl/praat/manual/Voice_2__Jitter.html</a>). This can be a bit overwhelming or difficult to understand which measure to use and why, or can lead to multiple colinear comparisons. To address this, by default, Voice Lab returns a the first component from a principal components analysis of those jitter algorithms taken across all selected voices. The underlying reasoning here is that each of these algorithms measures something about how noisy the voice is due to perturbations in period length. The PCA finds what is common about all of these measures of noise, and gives you a score relative to your sample. With a large enough sample, the PCA score should be a more robust measure of jitter than any single measurement. Voice Lab uses use it’s {ref}`automated pitch floor and ceiling algorithm.&lt;floor-ceiling&gt;` to set analysis parameters.</p>
<p>Jitter Measures:</p>
<ul class="simple">
<li><p>Jitter (local)</p></li>
<li><p>Jitter (local, absolute)</p></li>
<li><p>Jitter (rap)</p></li>
<li><p>Jitter (ppq5)</p></li>
<li><p>Jitter (ddp)</p></li>
</ul>
<p><a href="#id89"><span class="problematic" id="id90">``</span></a><a href="#id91"><span class="problematic" id="id92">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureJitterNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id93"><span class="problematic" id="id94">``</span></a><a href="#id95"><span class="problematic" id="id96">`</span></a></p>
<p>(shimmer)=</p>
<p>### Measure Shimmer</p>
<p>This measures and returns values of all of [Praat’s shimmer algorithms](<a class="reference external" href="http://www.fon.hum.uva.nl/praat/manual/Voice_3__Shimmer.html">http://www.fon.hum.uva.nl/praat/manual/Voice_3__Shimmer.html</a>). This can be a bit overwhelming or difficult to understand which measure to use and why, or can lead to multiple colinear comparisons. To address this, by default, Voice Lab returns a the first component from a principal components analysis of those shimmer algorithms taken across all selected voices. The underlying reasoning here is that each of these algorithms measures something about how noisy the voice is due to perturbations in amplitude of periods. The PCA finds what is common about all of these measures of noise, and gives you a score relative to your sample. With a large enough sample, the PCA score should be a more robust measure of shimmer than any single measurement. Voice Lab uses use it’s {ref}`automated pitch floor and ceiling algorithm.&lt;floor-ceiling&gt;` to set analysis parameters.</p>
<p>Shimmer Measures:</p>
<ul class="simple">
<li><p>Shimmer (local)</p></li>
<li><p>Shimmer (local, dB)</p></li>
<li><p>Shimmer (apq3)</p></li>
<li><p>Shimmer (aqp5)</p></li>
<li><p>Shimmer (apq11)</p></li>
<li><p>Shimmer (ddp)</p></li>
</ul>
<p><a href="#id97"><span class="problematic" id="id98">``</span></a><a href="#id99"><span class="problematic" id="id100">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureShimmerNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id101"><span class="problematic" id="id102">``</span></a><a href="#id103"><span class="problematic" id="id104">`</span></a></p>
<p>### Measure LTAS</p>
<p>This measures several items from the Long-Term Average Spectrum using Praat’s default settings.</p>
<ul class="simple">
<li><p>mean (dB)</p></li>
<li><p>slope (dB)</p></li>
<li><p>local peak height (dB)</p></li>
<li><p>standard deviation (dB)</p></li>
<li><p>spectral tilt slope (dB/Hz)</p></li>
<li><p>spectral tilt intercept (dB)</p></li>
</ul>
<p>You can adjust:
- Pitch correction
- Bandwidth
- Max Frequency
- Shortest and longest periods
- Maximum period factor</p>
<p><a href="#id105"><span class="problematic" id="id106">``</span></a><a href="#id107"><span class="problematic" id="id108">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureLTASNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id109"><span class="problematic" id="id110">``</span></a><a href="#id111"><span class="problematic" id="id112">`</span></a></p>
<p>### Measure MFCC</p>
<p>This node measures the first 24 Mel Cepstral Coeffecients of the sound.  There are no options to set. If you want fewer coeffecients, you can delete the one’s you don’t want. If you need the same number of values for each sound for Machine Learning, make sure the sounds are the same length before running the analysis.</p>
<p><a href="#id113"><span class="problematic" id="id114">``</span></a><a href="#id115"><span class="problematic" id="id116">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureMFCCNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id117"><span class="problematic" id="id118">``</span></a><a href="#id119"><span class="problematic" id="id120">`</span></a></p>
<p>### Measure Spectral Shape</p>
<p>This measures spectral:
- Centre of Gravity
- Standard Deviation
- Kurtosis
- Band Energy Difference
- Band Density Difference</p>
<p><a href="#id121"><span class="problematic" id="id122">``</span></a><a href="#id123"><span class="problematic" id="id124">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureSpectralShapeNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id125"><span class="problematic" id="id126">``</span></a><a href="#id127"><span class="problematic" id="id128">`</span></a></p>
<p>### Measure Spectral Tilt</p>
<p>This measures spectral tilt by returning the slope of a regression between freqeuncy and amplitude of each sound. This is from a script written by Michael J. Owren, with sorting errors corrected. This is not the same equation in Voice Sauce.</p>
<p>Owren, M.J. GSU Praat Tools: Scripts for modifying and analyzing sounds using Praat acoustics software. Behavior Research Methods (2008) 40:  822–829. &lt;<a class="reference external" href="https://doi.org/10.3758/BRM.40.3.822">https://doi.org/10.3758/BRM.40.3.822</a>&gt;</p>
<p><a href="#id129"><span class="problematic" id="id130">``</span></a><a href="#id131"><span class="problematic" id="id132">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureSpectralTiltNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id133"><span class="problematic" id="id134">``</span></a><a href="#id135"><span class="problematic" id="id136">`</span></a></p>
<p>### Measure Speech Rate</p>
<p>This function is an implementation of the Praat script published here:
De Jong, N.H. &amp; Wempe, T. (2009). Praat script to detect syllable nuclei and measure speech rate automatically. Behavior research methods, 41 (2), 385 - 390.</p>
<p>Voice Lab used version 2 of the script, available [here](<a class="reference external" href="https://sites.google.com/site/speechrate/Home/praat-script-syllable-nuclei-v2">https://sites.google.com/site/speechrate/Home/praat-script-syllable-nuclei-v2</a>).</p>
<p>This returns:
: - Number of Syllables</p>
<blockquote>
<div><ul class="simple">
<li><p>Number of Pauses</p></li>
<li><p>Duration(s)</p></li>
<li><p>Phonation Time(s)</p></li>
<li><p>Speech Rate (Number of Syllables / Duration)</p></li>
<li><p>Articulation Rate (Number of Syllables / Phonation Time)</p></li>
<li><p>Average Syllable Duration (Speaking Time / Number of Syllables)</p></li>
</ul>
</div></blockquote>
<p>You can adjust:
- silence threshold {python}`mindb`</p>
<ul class="simple">
<li><p>mimimum dip between peaks (dB) {python}`mindip`. This should be between 2-4. Try 4 for clean and filtered sounds, and lower numbers for noisier sounds.</p></li>
<li><p>minimum pause length {python}`minpause`</p></li>
</ul>
<p>This command really only words on sounds with a few syllables, since Voice Lab is measuring how fast someone speaks. For monosyllabic sounds, use the {ref}`Measure Duration function.&lt;Duration&gt;`</p>
<p><a href="#id137"><span class="problematic" id="id138">``</span></a><a href="#id139"><span class="problematic" id="id140">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureSpeechRateNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id141"><span class="problematic" id="id142">``</span></a><a href="#id143"><span class="problematic" id="id144">`</span></a></p>
<p>## Manipulation Nodes</p>
<p>### Lower Pitch</p>
<p>This lowers pitch using the PSOLA method. By default, this lowers  by 0.5 ERBs (Equivalent Rectangular Bandwidths) which is about 20 Hz at a 120 Hz pitch centre and about -/+ 25 Hz at a 240 Hz pitch centre. By default VoiceLab also normalizes intensity to 70 dB RMS, but you can turn this off by deselecting the box in the Settings tab.</p>
<p><a href="#id145"><span class="problematic" id="id146">``</span></a><a href="#id147"><span class="problematic" id="id148">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.ManipulatePitchLowerNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id149"><span class="problematic" id="id150">``</span></a><a href="#id151"><span class="problematic" id="id152">`</span></a></p>
<p>### Raise Pitch</p>
<p>This raises pitch using the PSOLA method. By default, this lowers  by 0.5 ERBs (Equivalent Rectangular Bandwidths) which is about 20 Hz at a 120 Hz pitch centre and about -/+ 25 Hz at a 240 Hz pitch centre. By default VoiceLab also normalizes intensity to 70 dB RMS, but you can turn this off by deselecting the box in the Settings tab.</p>
<p><a href="#id153"><span class="problematic" id="id154">``</span></a><a href="#id155"><span class="problematic" id="id156">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.ManipulatePitchHigherNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id157"><span class="problematic" id="id158">``</span></a><a href="#id159"><span class="problematic" id="id160">`</span></a></p>
<p>### Lower Formants</p>
<p>This lowers formants using Praat’s Change Gender Function. By default, Formants are lowered by 15%. This manipulation resamples a sound by the Formant scaling factor (which can be altered in the Settings tab). Then, the sampling rate is overriden to the sound’s original sampling rate. Then PSOLA is employed to stretch time and pitch back (separately) into their original values. By default VoiceLab also normalizes intensity to 70 dB RMS, but you can turn this off by deselecting the box in the Settings tab.</p>
<p><a href="#id161"><span class="problematic" id="id162">``</span></a><a href="#id163"><span class="problematic" id="id164">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.ManipulateLowerFormantsNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id165"><span class="problematic" id="id166">``</span></a><a href="#id167"><span class="problematic" id="id168">`</span></a></p>
<p>### Raise Formants</p>
<p>This raises formants using Praat’s Change Gender Function. By default, Formants are raised by 15%. This manipulation resamples a sound by the Formant scaling factor (which can be altered in the Settings tab). Then, the sampling rate is overriden to the sound’s original sampling rate. Then PSOLA is employed to stretch time and pitch back (separately) into their original values. By default VoiceLab also normalizes intensity to 70 dB RMS, but you can turn this off by deselecting the box in the Settings tab.</p>
<p><a href="#id169"><span class="problematic" id="id170">``</span></a><a href="#id171"><span class="problematic" id="id172">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.ManipulateRaiseFormantsNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id173"><span class="problematic" id="id174">``</span></a><a href="#id175"><span class="problematic" id="id176">`</span></a></p>
<p>### Lower Pitch and Formants</p>
<p>This manipulation lowers both pitch and formants in the same direction by the same or independent amounts. This uses the algorithm described in Manipulate Formants, but allows the user to scale or shift pitch to a designated degree. By default, pitch is also lowered by 15%. By default VoiceLab also normalizes intensity to 70 dB RMS, but you can turn this off by deselecting the box in the Settings tab.</p>
<p><a href="#id177"><span class="problematic" id="id178">``</span></a><a href="#id179"><span class="problematic" id="id180">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.ManipulateLowerPitchAndFormantsNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id181"><span class="problematic" id="id182">``</span></a><a href="#id183"><span class="problematic" id="id184">`</span></a></p>
<p>### Raise Pitch and Formants</p>
<p>This manipulation raises both pitch and formants in the same direction by the same or independent amounts. This uses the algorithm described in Manipulate Formants, but allows the user to scale or shift pitch to a designated degree. By default, pitch is also raised by 15%. By default VoiceLab also normalizes intensity to 70 dB RMS, but you can turn this off by deselecting the box in the Settings tab.</p>
<p><a href="#id185"><span class="problematic" id="id186">``</span></a><a href="#id187"><span class="problematic" id="id188">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.ManipulateRaisePitchAndFormantsNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id189"><span class="problematic" id="id190">``</span></a><a href="#id191"><span class="problematic" id="id192">`</span></a></p>
<p>### Reverse Sounds</p>
<p>This reverses the selected sounds. Use this if you want to play sounds backwards. Try a Led Zepplin or Beatles song.</p>
<p><a href="#id193"><span class="problematic" id="id194">``</span></a><a href="#id195"><span class="problematic" id="id196">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.ReverseSoundsNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id197"><span class="problematic" id="id198">``</span></a><a href="#id199"><span class="problematic" id="id200">`</span></a></p>
<p>### Resample Sounds</p>
<p>This is a quick and easy way to batch process resampling sounds. 44.1kHz is the default. Change this value in the Settings tab.</p>
<p><a href="#id201"><span class="problematic" id="id202">``</span></a><a href="#id203"><span class="problematic" id="id204">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.ResampleSoundsNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id205"><span class="problematic" id="id206">``</span></a><a href="#id207"><span class="problematic" id="id208">`</span></a></p>
<p>### Rotate Spectrum</p>
<p>This resamples the sound, rotates the selected sounds by 180 degrees and reverses it so it’s just the inverted frequency spectrum.
This script is from Chris Darwin and reproduced here with permission: [The original script can be found here](<a class="reference external" href="http://www.lifesci.sussex.ac.uk/home/Chris_Darwin/Praatscripts/Spectral%20Rotation">http://www.lifesci.sussex.ac.uk/home/Chris_Darwin/Praatscripts/Spectral%20Rotation</a>).</p>
<p>A similar technique was used here: Bédard, C., &amp; Belin, P. (2004). A “voice inversion effect?”. Brain and cognition, 55(2), 247-249.</p>
<p><a href="#id209"><span class="problematic" id="id210">``</span></a><a href="#id211"><span class="problematic" id="id212">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.RotateSpectrumNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id213"><span class="problematic" id="id214">``</span></a><a href="#id215"><span class="problematic" id="id216">`</span></a></p>
<p>### Scale Intensity</p>
<p>This scales intensity with Peak or RMS. Use this if you want your sounds to all be at an equivalent amplitude. By default intensity is normalized to 70 dB using RMS. If you use peak, it is scaled between -1 and 1, so pick a number between -1 and 1 to normalize to peak.</p>
<p><a href="#id217"><span class="problematic" id="id218">``</span></a><a href="#id219"><span class="problematic" id="id220">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.ScaleIntensityNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id221"><span class="problematic" id="id222">``</span></a><a href="#id223"><span class="problematic" id="id224">`</span></a></p>
<p>### Truncate Sounds</p>
<p>This trims and/or truncates sounds. You can trim a % of time off the ends of the sound, or voicelab can automatically detect silences at the beginning and end of the sound, and clip those out also.
If you have trouble with trimming silences, try adjusting the silence ratio in the Settings tab.</p>
<p><a href="#id225"><span class="problematic" id="id226">``</span></a><a href="#id227"><span class="problematic" id="id228">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.ManipulateTruncateSoundsNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id229"><span class="problematic" id="id230">``</span></a><a href="#id231"><span class="problematic" id="id232">`</span></a></p>
<p>## Visualization Nodes</p>
<p>### Spectrograms</p>
<p><code class="docutils literal notranslate"><span class="pre">`{image}</span> <span class="pre">_static/spectrogram.png</span>
<span class="pre">:alt:</span> <span class="pre">Spectrogram</span>
<span class="pre">:width:</span> <span class="pre">400</span>
<span class="pre">`</span></code></p>
<p>VoiceLab creates full colour spectrograms. By default we use a wide-band window. You can adjust the window length. For example, for a narrow-band spectrogram, you can try 0.005 as a window length. You can also select a different colour palate. You can also overlay pitch, the first four formant frequencies, and intensity measures on the spectrogram.</p>
<p><a href="#id233"><span class="problematic" id="id234">``</span></a><a href="#id235"><span class="problematic" id="id236">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.VisualizeVoiceNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id237"><span class="problematic" id="id238">``</span></a><a href="#id239"><span class="problematic" id="id240">`</span></a></p>
<p>### Power Spectra</p>
<p><code class="docutils literal notranslate"><span class="pre">`{image}</span> <span class="pre">_static/power_spectrum.png</span>
<span class="pre">:alt:</span> <span class="pre">Power</span> <span class="pre">spectrum</span>
<span class="pre">:width:</span> <span class="pre">400</span>
<span class="pre">`</span></code></p>
<p>VoiceLab creates power spectra of sounds and overlays an LPC curve over the top.</p>
<p><a href="#id241"><span class="problematic" id="id242">``</span></a><a href="#id243"><span class="problematic" id="id244">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.VisualizeSpectrumNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id245"><span class="problematic" id="id246">``</span></a><a href="#id247"><span class="problematic" id="id248">`</span></a></p>
<p>% This Sphynx rst file depends on sphinxcontrib-inlinesyntaxhighlight</p>
<p># Voice Lab Interface</p>
<p><code class="docutils literal notranslate"><span class="pre">`{eval-rst}</span>
<span class="pre">..</span> <span class="pre">highlight::</span> <span class="pre">rst</span>
<span class="pre">`</span></code></p>
<p><a href="#id249"><span class="problematic" id="id250">``</span></a><a href="#id251"><span class="problematic" id="id252">`</span></a>{eval-rst}
.. role:: python(code)</p>
<blockquote>
<div><p>:langua.. This Sphynx rst file depends on sphinxcontrib-inlinesyntaxhighlight</p>
</div></blockquote>
<p><a href="#id253"><span class="problematic" id="id254">``</span></a><a href="#id255"><span class="problematic" id="id256">`</span></a></p>
<p># Voice Lab Interface</p>
<p><code class="docutils literal notranslate"><span class="pre">`{eval-rst}</span>
<span class="pre">..</span> <span class="pre">highlight::</span> <span class="pre">rst</span>
<span class="pre">`</span></code></p>
<p><a href="#id257"><span class="problematic" id="id258">``</span></a><a href="#id259"><span class="problematic" id="id260">`</span></a>{eval-rst}
.. role:: python(code)</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">language<span class="colon">:</span></dt>
<dd class="field-odd"><p>python</p>
</dd>
</dl>
</div></blockquote>
<p><a href="#id261"><span class="problematic" id="id262">``</span></a><a href="#id263"><span class="problematic" id="id264">`</span></a></p>
<p><a href="#id265"><span class="problematic" id="id266">``</span></a><a href="#id267"><span class="problematic" id="id268">`</span></a>{eval-rst}
.. toctree:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">:</span><span class="n">numbered</span><span class="p">:</span>
<span class="p">:</span><span class="n">maxdepth</span><span class="p">:</span> <span class="mi">2</span>
</pre></div>
</div>
<p><a href="#id269"><span class="problematic" id="id270">``</span></a><a href="#id271"><span class="problematic" id="id272">`</span></a></p>
<p>Voice Lab is an automated voice analysis software. What this software does is allow you to measure, manipulate, and visualize many voices at once, without messing with analysis parameters. You can also save all of your data, analysis parameters, manipulated voices, and full colour spectrograms with the press of one button.</p>
<p>Voice Lab is written in Python and relies heavily on a package called parselmouth-praat. parselmouth-praat is a Python package that essentially turns Praat’s source code written in C and C++ into a Pythonic interface. What that means is that any praat measurement in this software is using actual Praat source code, so you can trust the underlying algorithms. Voice Lab figures out all of the analysis parameters for you, but you can always use your own, and these are the same parameters as in Praat, and they do the exact same thing because it is Praat’s source code powering everything. That means if you are a beginner an expert, or anything in-between, you can use this software to automate your acoustical analyses.</p>
<p>All of the code is open source and available on our GitHub repository, so if this manual isn’t in-depth enough, and you want to see exactly what’s going on, go for it. It is under the MIT license, so you are free to do what you like with the software as long as you give us credit. For more info on that license, see here.</p>
<p>## Load Voices Tab</p>
<p><code class="docutils literal notranslate"><span class="pre">`{image}</span> <span class="pre">_static/LoadVoices.png</span>
<span class="pre">:alt:</span> <span class="pre">Load</span> <span class="pre">voices</span> <span class="pre">window</span>
<span class="pre">:width:</span> <span class="pre">400</span>
<span class="pre">`</span></code></p>
<p>### Load Sound File</p>
<p>Press this button to load sound files. You can load as many files as you like.
At the moment, Voice Lab processes the following file types:</p>
<ul class="simple">
<li><p>wav</p></li>
<li><p>mp3</p></li>
<li><p>aiff</p></li>
<li><p>ogg</p></li>
<li><p>aifc</p></li>
<li><p>au</p></li>
<li><p>nist</p></li>
<li><p>flac</p></li>
</ul>
<p>### Remove Sound File</p>
<p>Use this button to remove the selected sound file(s) from the list.</p>
<p>### Start</p>
<p>Pressing this begins analysis. If you want to run the default analysis, press this button.
If you want to select different analyses or adjust analysis parameters, go to the ‘Settings’ tab and press the ‘Advanced Settings’ button.
Only the files selected (in blue) will be analyzed. By default we will select all files.</p>
<p>(id7)=</p>
<p>## Settings Tab</p>
<p><code class="docutils literal notranslate"><span class="pre">`{image}</span> <span class="pre">_static/settings.png</span>
<span class="pre">:alt:</span> <span class="pre">Settings</span> <span class="pre">window</span>
<span class="pre">:width:</span> <span class="pre">400</span>
<span class="pre">`</span></code></p>
<p>To choose different analyses, select the {python}`Use Advanced Settings` checkbox. From here, you’ll be given the option to select different analyses. You can also change any analysis parameters. If you do change analysis parameters, make sure you know what you are doing, and remember that those same analysis parameters will be used on all voice files that are selected. If you don’t alter these parameters, we determine analysis parameters automatically for you, so they are tailored for each voice to give the best measurements.</p>
<p>### Save Results</p>
<p>Save Results saves two xlsx files. One is the results.xlsx file and one is the settings.xlsx file. Here you can choose the directory you want to save the files into. You don’t have to click on a file, just go to the directory and press the button.</p>
<p>#### results.xlsx</p>
<p>The results file saves all of the voice measurements that you made. Each measurement gets a separate tab in the xlsx file.</p>
<p>#### settings.xlsx</p>
<p>This file saves all of the parameters used in each measurement. Each measurement gets a separate tab in the xlsx file. This is great if you want to know what happened. It can also accompany a manuscript or paper to help others replicate analyses.</p>
<p>### Results Tab</p>
<p><code class="docutils literal notranslate"><span class="pre">`{image}</span> <span class="pre">_static/output_window.png</span>
<span class="pre">:alt:</span> <span class="pre">Results</span> <span class="pre">window</span>
<span class="pre">:width:</span> <span class="pre">400</span>
<span class="pre">`</span></code></p>
<p>This is where you can view results. You can select each voice file on the left and view each measurement result on the bottom frame. You can also view your spectrograms in the spectrogram window. You can change the size of any of these frames in order to see things better. Press {python}`Save Results` to save data. All data (results &amp; settings), manipulated voices, and spectrograms are saved automatically when this button is pressed. All you have to do is choose which folder to save into. Don’t worry about picking file names, Voice Lab will make those automatically for you.</p>
<p>#### Output formats</p>
<ul class="simple">
<li><p>All data files are saved as xlsx</p></li>
<li><p>All sound files are saved as wav</p></li>
<li><p>All image files are saved as png</p></li>
</ul>
<p># Documentation and API Reference</p>
<p>This API is not yet complete. It is a work in progress. But, for now, there’s enough for you to run any node as long
as you can understand the code.  Reproducing Voicelab’s exact behaviour in the command line is a bit more difficult as
there is a state dictionary and and {python}`end()` method for some nodes.</p>
<p>All nodes can be imported and run without the VoiceLab GUI if you program their execution in Python.</p>
<p>You’ll need to supply: {python}`args[‘file_path’]`, which is the file path, and
{python}`args[‘voice’]`, which is the {python}`parselmouth.Sound` object created by running
{python}`parselmouth.Sound(args[‘file_path’])`.  You may also set additional parameters by creating an
instance of a node, and setting the dictionary {python}`args` to the appropriate values as specified
in each node. The output of each node is a dictionary of the results. If the node is a manipulation
node, it will return a {python}`parselmouth.Sound` object. If the node is a plot, it will return a matplotlib figure.
Otherwise, it will return mixed types of floats, integers, strings, and lists in the dictionary.</p>
<p>Validation analyses for automatic analysis settings and Energy can be found [here&lt;<a class="reference external" href="https://osf.io/3wr6k/files/">https://osf.io/3wr6k/files/</a>&gt;][here&lt;<a class="reference external" href="https://osf.io/3wr6k/files/">https://osf.io/3wr6k/files/</a>&gt;].</p>
<p>## Automated Settings</p>
<p>VoiceLab uses automated settings for pitch floor and ceiling, and also uses these to set the centre frequency parameter in the FormantPath formant analysis.</p>
<p>(id16)=</p>
<p>### Automated pitch floor and ceiling parameters</p>
<p>Praat suggests adjusting pitch settings based on [gender](<a class="reference external" href="http://www.fon.hum.uva.nl/praat/manual/Intro_4_2__Configuring_the_pitch_contour.html">http://www.fon.hum.uva.nl/praat/manual/Intro_4_2__Configuring_the_pitch_contour.html</a>) . It’s not gender per se that is important, but the pitch of voice. To mitigate this, VoiceLab first casts a wide net in  floor and ceiling settings to learn the range of probable fundamental frequencies is a voice. Then it remeasures the voice pitch using different settings for higher and lower pitched voices. VoiceLab by default uses employs {python}`very accurate`. VoiceLab returns {python}`minimum pitch`, {python}`maximum pitch`, {python}`mean pitch`, and {python}`standard deviation of pitch`. By default VoiceLab uses  autocorrelation for {ref}`Measuring Pitch&lt;Pitch&gt;`, and cross-correlation for {ref}`harmonicity&lt;HNR&gt;`, {ref}`Jitter&lt;Jitter&gt;`, and {ref}`Shimmer&lt;Shimmer&gt;`,</p>
<p>## Measurement Nodes</p>
<p>(id19)=</p>
<p>### Measure Pitch</p>
<p>This measures voice pitch or fundamental frequency. Users can measure pitch using any number of the following algorithms:
: - Praat Autocorrelation</p>
<blockquote>
<div><ul class="simple">
<li><p>Praat Cross Correlation</p></li>
<li><p>Yin (From Librosa)</p></li>
<li><p>Subharmonics (from Open Sauce)</p></li>
</ul>
</div></blockquote>
<p>By default it will measure all of these.</p>
<p>This uses Praat’s {python}`Sound: To Pitch (ac)…`, by default. You can also use the cross-correlation algorithm: {python}`Sound: To Pitch (cc)…`. For full details on these algorithms, see the [praat manual pitch page](<a class="reference external" href="http://www.fon.hum.uva.nl/praat/manual/Pitch.html">http://www.fon.hum.uva.nl/praat/manual/Pitch.html</a>).
{python}`Measure Pitch` returns the following measurements:</p>
<p>&gt; - A list of the pitch values
&gt; - Minimum Pitch
&gt; - Maximum Pitch
&gt; - Mean Pitch
&gt; - Standard Deviation of Pitch
&gt; - Pitch Floor (used to set window length)
&gt; - Pitch Ceiling (no candidates above this value will be considered)</p>
<p>We use the automated pitch floor and ceiling parameters described {ref}`here.&lt;floor-ceiling&gt;`</p>
<p>#### Measure Pitch Yin</p>
<p>This is the Yin implementation from Librosa.  This is now run out of the Measure Pitch Node.</p>
<p><a href="#id273"><span class="problematic" id="id274">``</span></a><a href="#id275"><span class="problematic" id="id276">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasurePitchNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id277"><span class="problematic" id="id278">``</span></a><a href="#id279"><span class="problematic" id="id280">`</span></a></p>
<p>#### Measure Subharmonics</p>
<p>This measures subharmonic pitch and subharmonic to harmonic ratio. Subharmonic to harmonic ratio and Subharmonic pitch are measures from Open Sauce (Yu et al., 2019), a Python port of Voice Sauce (Shue et al., 2011).  These measurements do not use any Praat or Parselmouth code.  As in (Shue et al., 2011) and (Yu et al., 2019), subharmonic raw values are padded with NaN values to 201 data points.</p>
<p><a href="#id281"><span class="problematic" id="id282">``</span></a><a href="#id283"><span class="problematic" id="id284">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureSHRPNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id285"><span class="problematic" id="id286">``</span></a><a href="#id287"><span class="problematic" id="id288">`</span></a></p>
<p>(id23)=</p>
<p>### Measure CPP (Cepstral Peak Prominence)</p>
<p>This measures Cepstral Peak Prominance in Praat. You can adjust interpolation, qeufrency upper and lower bounds, line type, and fit method.</p>
<p><a href="#id289"><span class="problematic" id="id290">``</span></a><a href="#id291"><span class="problematic" id="id292">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureCPPNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id293"><span class="problematic" id="id294">``</span></a><a href="#id295"><span class="problematic" id="id296">`</span></a></p>
<p>(id25)=</p>
<p>### Measure Duration</p>
<p>This measures the full duration of the sound file. There are no parameters to adjust.</p>
<p>(id27)=</p>
<p>### Measure Energy</p>
<p>This is my port of VoiceSauce’s Energy Algorithm.  It is different than the old RMS Energy algorithm in previous versions of VoiceLab. This code is not in OpenSauce.</p>
<p><a href="#id297"><span class="problematic" id="id298">``</span></a><a href="#id299"><span class="problematic" id="id300">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureEnergyNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id301"><span class="problematic" id="id302">``</span></a><a href="#id303"><span class="problematic" id="id304">`</span></a></p>
<p>(id29)=</p>
<p>### Measure Formants</p>
<p>This returns the mean of the first 4 formant frequencies of the voice using the {python}`To FormantPath` algorithm using
5.5 maximum number of formants and a variable centre frequency, set automatically or user-specified.  All other values
are Praat defaults for Formant Path.  Formant path picks the best formant ceiling value by fitting each prediction to a
polynomial curve, and choosing the best fit for each formant. The centre frequency is determined in the automatic
settings You can also use your own settings for {python}`To Formant Burg…` if you want to.</p>
<p><a href="#id305"><span class="problematic" id="id306">``</span></a><a href="#id307"><span class="problematic" id="id308">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureFormantNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id309"><span class="problematic" id="id310">``</span></a><a href="#id311"><span class="problematic" id="id312">`</span></a></p>
<p>### Measure Vocal Tract Length Estimates</p>
<p>This returns the following vocal tract length estimates:</p>
<p>#### Average Formant</p>
<p>This calculates the mean $frac {sum _{i=1}^{n} {f_i}}{n}$ of the first four formant frequencies for each sound.</p>
<p>Pisanski, K., &amp; Rendall, D. (2011). The prioritization of voice fundamental frequency or formants in listeners’ assessments of speaker size, masculinity, and attractiveness. The Journal of the Acoustical Society of America, 129(4), 2201-2212.</p>
<p>#### Principle Components Analysis</p>
<p>This returns the first factor from a Principle Components Analysis (PCA) of the 4 formants.</p>
<p>Babel, M., McGuire, G., &amp; King, J. (2014). Towards a more nuanced view of vocal attractiveness. PloS one, 9(2), e88616.</p>
<p>#### Geometric Mean</p>
<p>This calculates the geometric mean $left(prod _{i=1}^{n}f_{i}right)^{frac {1}{n}}$ of the first 4 formant frequencies for each sound.</p>
<p>Smith, D. R., &amp; Patterson, R. D. (2005). The interaction of glottal-pulse rate andvocal-tract length in judgements of speaker size, sex, and age.Journal of theAcoustical Society of America, 118, 3177e3186.</p>
<p>#### Formant Dispersion</p>
<p>$frac {sum _{i=2}^{n} {f_i - f_{i-1}}}{n}$</p>
<p>Fitch, W. T. (1997). Vocal-tract length and formant frequency dispersion correlate with body size in rhesus macaques.Journal of the Acoustical Society of America,102,1213e1222.</p>
<p>#### VTL</p>
<p>$frac {sum _{i=1}^{n} (2n-1) frac {f_i}{4c}}{n}$</p>
<p>Fitch, W. T. (1997). Vocal-tract length and formant frequency dispersion correlate with body size in rhesus macaques.Journal of the Acoustical Society of America,102,1213e1222.</p>
<p>Titze, I. R. (1994).Principles of voice production. Englewood Cliffs, NJ: Prentice Hall.</p>
<p>#### VTL Δf</p>
<p>$f_i$ = The slope of 0 intercept regression between $F_i = frac {(2i-1)}{2} Δf$ and the mean of each of the first 4 formant frequencies.</p>
<p>$VTL f_i = frac {sum _{i=1}^{n} (2n-1)(frac {c}{4f_i})}{n}$</p>
<p>$VTL Delta f = frac {c}{2Δf}$</p>
<p>Reby,D.,&amp;McComb,K.(2003).Anatomical constraints generate honesty: acoustic cues to age and weight in the roars of red deer stags. Animal Behaviour, 65,519e530.</p>
<p>(id38)=</p>
<p>#### Measure Formant Positions Node</p>
<p>This node measures formant position. This node is executed by MeasureVocalTractEstimatesNode.</p>
<p>Formant Position is set to only run on samples of 30 or greater because this measure is based on scaling the data. Without a large enough sample, this measurement could be suspicious.</p>
<p>The algorithm is as follows:
: - First, measure formants at each gottal pulse.</p>
<blockquote>
<div><ul>
<li><p>Second, scale each formant separately.</p></li>
<li><p>Third, find the mean of the scaled formants.</p>
<p>&gt; - $frac{1}{n} {sum _{i=1}^{n}{f_i}}$</p>
</li>
</ul>
</div></blockquote>
<p>This algorithm deviates from the original in that it checks the data for a normal distribution before applying the z-score. If it is not normally distributed, it uses Scikit Learn’s [Robust Scalar](<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html">https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html</a>)
The scalar method is recorded in the voicelab_settings.xlsx file.</p>
<p>Puts, D. A., Apicella, C. L., &amp; Cárdenas, R. A. (2011). Masculine voices signal men’s threat potential in forager and industrial societies. Proceedings of the Royal Society B: Biological Sciences, 279(1728), 601-609.</p>
<p><a href="#id313"><span class="problematic" id="id314">``</span></a><a href="#id315"><span class="problematic" id="id316">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureVocalTractEstimatesNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id317"><span class="problematic" id="id318">``</span></a><a href="#id319"><span class="problematic" id="id320">`</span></a></p>
<p><a href="#id321"><span class="problematic" id="id322">``</span></a><a href="#id323"><span class="problematic" id="id324">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureFormantPositionsNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id325"><span class="problematic" id="id326">``</span></a><a href="#id327"><span class="problematic" id="id328">`</span></a></p>
<p>(id40)=</p>
<p>### Measure Harmonicity</p>
<p>This measures mean harmonics-to-noise-ratio using automatic floor and ceiling settings described {ref}`here.&lt;floor-ceiling&gt;`  Full details of the algorithm can be found in the [Praat Manual Harmonicity Page&lt;<a class="reference external" href="http://www.fon.hum.uva.nl/praat/manual/Harmonicity.html">http://www.fon.hum.uva.nl/praat/manual/Harmonicity.html</a>&gt;][praat manual harmonicity page&lt;<a class="reference external" href="http://www.fon.hum.uva.nl/praat/manual/harmonicity.html">http://www.fon.hum.uva.nl/praat/manual/harmonicity.html</a>&gt;]. By default Voice Lab use {python}`To Harmonicity (cc)..`. You can select {python}`To Harmonicity (ac)` or change any other Praat parameters if you wish.</p>
<p><a href="#id329"><span class="problematic" id="id330">``</span></a><a href="#id331"><span class="problematic" id="id332">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureHarmonicityNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id333"><span class="problematic" id="id334">``</span></a><a href="#id335"><span class="problematic" id="id336">`</span></a></p>
<p>### Measure Intensity</p>
<p>This returns the mean of Praat’s  {python}`Sound: To Intensity…` function in dB. You can adjust the minimum pitch parameter. For more information, see Praat
s [Configuring the intensity contour Page](<a class="reference external" href="https://www.fon.hum.uva.nl/praat/manual/Intro_6_2__Configuring_the_intensity_contour.html">https://www.fon.hum.uva.nl/praat/manual/Intro_6_2__Configuring_the_intensity_contour.html</a>).</p>
<p><a href="#id337"><span class="problematic" id="id338">``</span></a><a href="#id339"><span class="problematic" id="id340">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureIntensityNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id341"><span class="problematic" id="id342">``</span></a><a href="#id343"><span class="problematic" id="id344">`</span></a></p>
<p>(id43)=</p>
<p>### Measure Jitter</p>
<p>This measures and returns values of all of [Praat’s jitter algorithms](<a class="reference external" href="http://www.fon.hum.uva.nl/praat/manual/Voice_2__Jitter.html">http://www.fon.hum.uva.nl/praat/manual/Voice_2__Jitter.html</a>). This can be a bit overwhelming or difficult to understand which measure to use and why, or can lead to multiple colinear comparisons. To address this, by default, Voice Lab returns a the first component from a principal components analysis of those jitter algorithms taken across all selected voices. The underlying reasoning here is that each of these algorithms measures something about how noisy the voice is due to perturbations in period length. The PCA finds what is common about all of these measures of noise, and gives you a score relative to your sample. With a large enough sample, the PCA score should be a more robust measure of jitter than any single measurement. Voice Lab uses use it’s {ref}`automated pitch floor and ceiling algorithm.&lt;floor-ceiling&gt;` to set analysis parameters.</p>
<p>Jitter Measures:</p>
<ul class="simple">
<li><p>Jitter (local)</p></li>
<li><p>Jitter (local, absolute)</p></li>
<li><p>Jitter (rap)</p></li>
<li><p>Jitter (ppq5)</p></li>
<li><p>Jitter (ddp)</p></li>
</ul>
<p><a href="#id345"><span class="problematic" id="id346">``</span></a><a href="#id347"><span class="problematic" id="id348">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureJitterNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id349"><span class="problematic" id="id350">``</span></a><a href="#id351"><span class="problematic" id="id352">`</span></a></p>
<p>(id45)=</p>
<p>### Measure Shimmer</p>
<p>This measures and returns values of all of [Praat’s shimmer algorithms](<a class="reference external" href="http://www.fon.hum.uva.nl/praat/manual/Voice_3__Shimmer.html">http://www.fon.hum.uva.nl/praat/manual/Voice_3__Shimmer.html</a>). This can be a bit overwhelming or difficult to understand which measure to use and why, or can lead to multiple colinear comparisons. To address this, by default, Voice Lab returns a the first component from a principal components analysis of those shimmer algorithms taken across all selected voices. The underlying reasoning here is that each of these algorithms measures something about how noisy the voice is due to perturbations in amplitude of periods. The PCA finds what is common about all of these measures of noise, and gives you a score relative to your sample. With a large enough sample, the PCA score should be a more robust measure of shimmer than any single measurement. Voice Lab uses use it’s {ref}`automated pitch floor and ceiling algorithm.&lt;floor-ceiling&gt;` to set analysis parameters.</p>
<p>Shimmer Measures:</p>
<ul class="simple">
<li><p>Shimmer (local)</p></li>
<li><p>Shimmer (local, dB)</p></li>
<li><p>Shimmer (apq3)</p></li>
<li><p>Shimmer (aqp5)</p></li>
<li><p>Shimmer (apq11)</p></li>
<li><p>Shimmer (ddp)</p></li>
</ul>
<p><a href="#id353"><span class="problematic" id="id354">``</span></a><a href="#id355"><span class="problematic" id="id356">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureShimmerNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id357"><span class="problematic" id="id358">``</span></a><a href="#id359"><span class="problematic" id="id360">`</span></a></p>
<p>### Measure LTAS</p>
<p>This measures several items from the Long-Term Average Spectrum using Praat’s default settings.</p>
<ul class="simple">
<li><p>mean (dB)</p></li>
<li><p>slope (dB)</p></li>
<li><p>local peak height (dB)</p></li>
<li><p>standard deviation (dB)</p></li>
<li><p>spectral tilt slope (dB/Hz)</p></li>
<li><p>spectral tilt intercept (dB)</p></li>
</ul>
<p>You can adjust:
- Pitch correction
- Bandwidth
- Max Frequency
- Shortest and longest periods
- Maximum period factor</p>
<p><a href="#id361"><span class="problematic" id="id362">``</span></a><a href="#id363"><span class="problematic" id="id364">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureLTASNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id365"><span class="problematic" id="id366">``</span></a><a href="#id367"><span class="problematic" id="id368">`</span></a></p>
<p>### Measure MFCC</p>
<p>This node measures the first 24 Mel Cepstral Coeffecients of the sound.  There are no options to set. If you want fewer coeffecients, you can delete the one’s you don’t want. If you need the same number of values for each sound for Machine Learning, make sure the sounds are the same length before running the analysis.</p>
<p><a href="#id369"><span class="problematic" id="id370">``</span></a><a href="#id371"><span class="problematic" id="id372">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureMFCCNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id373"><span class="problematic" id="id374">``</span></a><a href="#id375"><span class="problematic" id="id376">`</span></a></p>
<p>### Measure Spectral Shape</p>
<p>This measures spectral:
- Centre of Gravity
- Standard Deviation
- Kurtosis
- Band Energy Difference
- Band Density Difference</p>
<p><a href="#id377"><span class="problematic" id="id378">``</span></a><a href="#id379"><span class="problematic" id="id380">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureSpectralShapeNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id381"><span class="problematic" id="id382">``</span></a><a href="#id383"><span class="problematic" id="id384">`</span></a></p>
<p>### Measure Spectral Tilt</p>
<p>This measures spectral tilt by returning the slope of a regression between freqeuncy and amplitude of each sound. This is from a script written by Michael J. Owren, with sorting errors corrected. This is not the same equation in Voice Sauce.</p>
<p>Owren, M.J. GSU Praat Tools: Scripts for modifying and analyzing sounds using Praat acoustics software. Behavior Research Methods (2008) 40:  822–829. &lt;<a class="reference external" href="https://doi.org/10.3758/BRM.40.3.822">https://doi.org/10.3758/BRM.40.3.822</a>&gt;</p>
<p><a href="#id385"><span class="problematic" id="id386">``</span></a><a href="#id387"><span class="problematic" id="id388">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureSpectralTiltNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id389"><span class="problematic" id="id390">``</span></a><a href="#id391"><span class="problematic" id="id392">`</span></a></p>
<p>### Measure Speech Rate</p>
<p>This function is an implementation of the Praat script published here:
De Jong, N.H. &amp; Wempe, T. (2009). Praat script to detect syllable nuclei and measure speech rate automatically. Behavior research methods, 41 (2), 385 - 390.</p>
<p>Voice Lab used version 2 of the script, available [here](<a class="reference external" href="https://sites.google.com/site/speechrate/Home/praat-script-syllable-nuclei-v2">https://sites.google.com/site/speechrate/Home/praat-script-syllable-nuclei-v2</a>).</p>
<p>This returns:
: - Number of Syllables</p>
<blockquote>
<div><ul class="simple">
<li><p>Number of Pauses</p></li>
<li><p>Duration(s)</p></li>
<li><p>Phonation Time(s)</p></li>
<li><p>Speech Rate (Number of Syllables / Duration)</p></li>
<li><p>Articulation Rate (Number of Syllables / Phonation Time)</p></li>
<li><p>Average Syllable Duration (Speaking Time / Number of Syllables)</p></li>
</ul>
</div></blockquote>
<p>You can adjust:
- silence threshold {python}`mindb`</p>
<ul class="simple">
<li><p>mimimum dip between peaks (dB) {python}`mindip`. This should be between 2-4. Try 4 for clean and filtered sounds, and lower numbers for noisier sounds.</p></li>
<li><p>minimum pause length {python}`minpause`</p></li>
</ul>
<p>This command really only words on sounds with a few syllables, since Voice Lab is measuring how fast someone speaks. For monosyllabic sounds, use the {ref}`Measure Duration function.&lt;Duration&gt;`</p>
<p><a href="#id393"><span class="problematic" id="id394">``</span></a><a href="#id395"><span class="problematic" id="id396">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureSpeechRateNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id397"><span class="problematic" id="id398">``</span></a><a href="#id399"><span class="problematic" id="id400">`</span></a></p>
<p>## Manipulation Nodes</p>
<p>### Lower Pitch</p>
<p>This lowers pitch using the PSOLA method. By default, this lowers  by 0.5 ERBs (Equivalent Rectangular Bandwidths) which is about 20 Hz at a 120 Hz pitch centre and about -/+ 25 Hz at a 240 Hz pitch centre. By default VoiceLab also normalizes intensity to 70 dB RMS, but you can turn this off by deselecting the box in the Settings tab.</p>
<p><a href="#id401"><span class="problematic" id="id402">``</span></a><a href="#id403"><span class="problematic" id="id404">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.ManipulatePitchLowerNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id405"><span class="problematic" id="id406">``</span></a><a href="#id407"><span class="problematic" id="id408">`</span></a></p>
<p>### Raise Pitch</p>
<p>This raises pitch using the PSOLA method. By default, this lowers  by 0.5 ERBs (Equivalent Rectangular Bandwidths) which is about 20 Hz at a 120 Hz pitch centre and about -/+ 25 Hz at a 240 Hz pitch centre. By default VoiceLab also normalizes intensity to 70 dB RMS, but you can turn this off by deselecting the box in the Settings tab.</p>
<p><a href="#id409"><span class="problematic" id="id410">``</span></a><a href="#id411"><span class="problematic" id="id412">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.ManipulatePitchHigherNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id413"><span class="problematic" id="id414">``</span></a><a href="#id415"><span class="problematic" id="id416">`</span></a></p>
<p>### Lower Formants</p>
<p>This lowers formants using Praat’s Change Gender Function. By default, Formants are lowered by 15%. This manipulation resamples a sound by the Formant scaling factor (which can be altered in the Settings tab). Then, the sampling rate is overriden to the sound’s original sampling rate. Then PSOLA is employed to stretch time and pitch back (separately) into their original values. By default VoiceLab also normalizes intensity to 70 dB RMS, but you can turn this off by deselecting the box in the Settings tab.</p>
<p><a href="#id417"><span class="problematic" id="id418">``</span></a><a href="#id419"><span class="problematic" id="id420">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.ManipulateLowerFormantsNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id421"><span class="problematic" id="id422">``</span></a><a href="#id423"><span class="problematic" id="id424">`</span></a></p>
<p>### Raise Formants</p>
<p>This raises formants using Praat’s Change Gender Function. By default, Formants are raised by 15%. This manipulation resamples a sound by the Formant scaling factor (which can be altered in the Settings tab). Then, the sampling rate is overriden to the sound’s original sampling rate. Then PSOLA is employed to stretch time and pitch back (separately) into their original values. By default VoiceLab also normalizes intensity to 70 dB RMS, but you can turn this off by deselecting the box in the Settings tab.</p>
<p><a href="#id425"><span class="problematic" id="id426">``</span></a><a href="#id427"><span class="problematic" id="id428">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.ManipulateRaiseFormantsNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id429"><span class="problematic" id="id430">``</span></a><a href="#id431"><span class="problematic" id="id432">`</span></a></p>
<p>### Lower Pitch and Formants</p>
<p>This manipulation lowers both pitch and formants in the same direction by the same or independent amounts. This uses the algorithm described in Manipulate Formants, but allows the user to scale or shift pitch to a designated degree. By default, pitch is also lowered by 15%. By default VoiceLab also normalizes intensity to 70 dB RMS, but you can turn this off by deselecting the box in the Settings tab.</p>
<p><a href="#id433"><span class="problematic" id="id434">``</span></a><a href="#id435"><span class="problematic" id="id436">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.ManipulateLowerPitchAndFormantsNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id437"><span class="problematic" id="id438">``</span></a><a href="#id439"><span class="problematic" id="id440">`</span></a></p>
<p>### Raise Pitch and Formants</p>
<p>This manipulation raises both pitch and formants in the same direction by the same or independent amounts. This uses the algorithm described in Manipulate Formants, but allows the user to scale or shift pitch to a designated degree. By default, pitch is also raised by 15%. By default VoiceLab also normalizes intensity to 70 dB RMS, but you can turn this off by deselecting the box in the Settings tab.</p>
<p><a href="#id441"><span class="problematic" id="id442">``</span></a><a href="#id443"><span class="problematic" id="id444">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.ManipulateRaisePitchAndFormantsNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id445"><span class="problematic" id="id446">``</span></a><a href="#id447"><span class="problematic" id="id448">`</span></a></p>
<p>### Reverse Sounds</p>
<p>This reverses the selected sounds. Use this if you want to play sounds backwards. Try a Led Zepplin or Beatles song.</p>
<p><a href="#id449"><span class="problematic" id="id450">``</span></a><a href="#id451"><span class="problematic" id="id452">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.ReverseSoundsNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id453"><span class="problematic" id="id454">``</span></a><a href="#id455"><span class="problematic" id="id456">`</span></a></p>
<p>### Resample Sounds</p>
<p>This is a quick and easy way to batch process resampling sounds. 44.1kHz is the default. Change this value in the Settings tab.</p>
<p><a href="#id457"><span class="problematic" id="id458">``</span></a><a href="#id459"><span class="problematic" id="id460">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.ResampleSoundsNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id461"><span class="problematic" id="id462">``</span></a><a href="#id463"><span class="problematic" id="id464">`</span></a></p>
<p>### Rotate Spectrum</p>
<p>This resamples the sound, rotates the selected sounds by 180 degrees and reverses it so it’s just the inverted frequency spectrum.
This script is from Chris Darwin and reproduced here with permission: [The original script can be found here](<a class="reference external" href="http://www.lifesci.sussex.ac.uk/home/Chris_Darwin/Praatscripts/Spectral%20Rotation">http://www.lifesci.sussex.ac.uk/home/Chris_Darwin/Praatscripts/Spectral%20Rotation</a>).</p>
<p>A similar technique was used here: Bédard, C., &amp; Belin, P. (2004). A “voice inversion effect?”. Brain and cognition, 55(2), 247-249.</p>
<p><a href="#id465"><span class="problematic" id="id466">``</span></a><a href="#id467"><span class="problematic" id="id468">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.RotateSpectrumNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id469"><span class="problematic" id="id470">``</span></a><a href="#id471"><span class="problematic" id="id472">`</span></a></p>
<p>### Scale Intensity</p>
<p>This scales intensity with Peak or RMS. Use this if you want your sounds to all be at an equivalent amplitude. By default intensity is normalized to 70 dB using RMS. If you use peak, it is scaled between -1 and 1, so pick a number between -1 and 1 to normalize to peak.</p>
<p><a href="#id473"><span class="problematic" id="id474">``</span></a><a href="#id475"><span class="problematic" id="id476">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.ScaleIntensityNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id477"><span class="problematic" id="id478">``</span></a><a href="#id479"><span class="problematic" id="id480">`</span></a></p>
<p>### Truncate Sounds</p>
<p>This trims and/or truncates sounds. You can trim a % of time off the ends of the sound, or voicelab can automatically detect silences at the beginning and end of the sound, and clip those out also.
If you have trouble with trimming silences, try adjusting the silence ratio in the Settings tab.</p>
<p><a href="#id481"><span class="problematic" id="id482">``</span></a><a href="#id483"><span class="problematic" id="id484">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.ManipulateTruncateSoundsNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id485"><span class="problematic" id="id486">``</span></a><a href="#id487"><span class="problematic" id="id488">`</span></a></p>
<p>## Visualization Nodes</p>
<p>### Spectrograms</p>
<p><code class="docutils literal notranslate"><span class="pre">`{image}</span> <span class="pre">_static/spectrogram.png</span>
<span class="pre">:alt:</span> <span class="pre">Spectrogram</span>
<span class="pre">:width:</span> <span class="pre">400</span>
<span class="pre">`</span></code></p>
<p>VoiceLab creates full colour spectrograms. By default we use a wide-band window. You can adjust the window length. For example, for a narrow-band spectrogram, you can try 0.005 as a window length. You can also select a different colour palate. You can also overlay pitch, the first four formant frequencies, and intensity measures on the spectrogram.</p>
<p><a href="#id489"><span class="problematic" id="id490">``</span></a><a href="#id491"><span class="problematic" id="id492">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.VisualizeVoiceNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id493"><span class="problematic" id="id494">``</span></a><a href="#id495"><span class="problematic" id="id496">`</span></a></p>
<p>### Power Spectra</p>
<p><code class="docutils literal notranslate"><span class="pre">`{image}</span> <span class="pre">_static/power_spectrum.png</span>
<span class="pre">:alt:</span> <span class="pre">Power</span> <span class="pre">spectrum</span>
<span class="pre">:width:</span> <span class="pre">400</span>
<span class="pre">`</span></code></p>
<p>VoiceLab creates power spectra of sounds and overlays an LPC curve over the top.</p>
<p><a href="#id497"><span class="problematic" id="id498">``</span></a><a href="#id499"><span class="problematic" id="id500">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.VisualizeSpectrumNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id501"><span class="problematic" id="id502">``</span></a><a href="#id503"><span class="problematic" id="id504">`</span></a></p>
<p>ge: python</p>
<p><a href="#id505"><span class="problematic" id="id506">``</span></a><a href="#id507"><span class="problematic" id="id508">`</span></a>{eval-rst}
.. toctree:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">:</span><span class="n">numbered</span><span class="p">:</span>
<span class="p">:</span><span class="n">maxdepth</span><span class="p">:</span> <span class="mi">2</span>
</pre></div>
</div>
<p><a href="#id509"><span class="problematic" id="id510">``</span></a><a href="#id511"><span class="problematic" id="id512">`</span></a></p>
<p>Voice Lab is an automated voice analysis software. What this software does is allow you to measure, manipulate, and visualize many voices at once, without messing with analysis parameters. You can also save all of your data, analysis parameters, manipulated voices, and full colour spectrograms with the press of one button.</p>
<p>Voice Lab is written in Python and relies heavily on a package called parselmouth-praat. parselmouth-praat is a Python package that essentially turns Praat’s source code written in C and C++ into a Pythonic interface. What that means is that any praat measurement in this software is using actual Praat source code, so you can trust the underlying algorithms. Voice Lab figures out all of the analysis parameters for you, but you can always use your own, and these are the same parameters as in Praat, and they do the exact same thing because it is Praat’s source code powering everything. That means if you are a beginner an expert, or anything in-between, you can use this software to automate your acoustical analyses.</p>
<p>All of the code is open source and available on our GitHub repository, so if this manual isn’t in-depth enough, and you want to see exactly what’s going on, go for it. It is under the MIT license, so you are free to do what you like with the software as long as you give us credit. For more info on that license, see here.</p>
<p>## Load Voices Tab</p>
<p><code class="docutils literal notranslate"><span class="pre">`{image}</span> <span class="pre">_static/LoadVoices.png</span>
<span class="pre">:alt:</span> <span class="pre">Load</span> <span class="pre">voices</span> <span class="pre">window</span>
<span class="pre">:width:</span> <span class="pre">400</span>
<span class="pre">`</span></code></p>
<p>### Load Sound File</p>
<p>Press this button to load sound files. You can load as many files as you like.
At the moment, Voice Lab processes the following file types:</p>
<ul class="simple">
<li><p>wav</p></li>
<li><p>mp3</p></li>
<li><p>aiff</p></li>
<li><p>ogg</p></li>
<li><p>aifc</p></li>
<li><p>au</p></li>
<li><p>nist</p></li>
<li><p>flac</p></li>
</ul>
<p>### Remove Sound File</p>
<p>Use this button to remove the selected sound file(s) from the list.</p>
<p>### Start</p>
<p>Pressing this begins analysis. If you want to run the default analysis, press this button.
If you want to select different analyses or adjust analysis parameters, go to the ‘Settings’ tab and press the ‘Advanced Settings’ button.
Only the files selected (in blue) will be analyzed. By default we will select all files.</p>
<p>(id71)=</p>
<p>## Settings Tab</p>
<p><code class="docutils literal notranslate"><span class="pre">`{image}</span> <span class="pre">_static/settings.png</span>
<span class="pre">:alt:</span> <span class="pre">Settings</span> <span class="pre">window</span>
<span class="pre">:width:</span> <span class="pre">400</span>
<span class="pre">`</span></code></p>
<p>To choose different analyses, select the {python}`Use Advanced Settings` checkbox. From here, you’ll be given the option to select different analyses. You can also change any analysis parameters. If you do change analysis parameters, make sure you know what you are doing, and remember that those same analysis parameters will be used on all voice files that are selected. If you don’t alter these parameters, we determine analysis parameters automatically for you, so they are tailored for each voice to give the best measurements.</p>
<p>### Save Results</p>
<p>Save Results saves two xlsx files. One is the results.xlsx file and one is the settings.xlsx file. Here you can choose the directory you want to save the files into. You don’t have to click on a file, just go to the directory and press the button.</p>
<p>#### results.xlsx</p>
<p>The results file saves all of the voice measurements that you made. Each measurement gets a separate tab in the xlsx file.</p>
<p>#### settings.xlsx</p>
<p>This file saves all of the parameters used in each measurement. Each measurement gets a separate tab in the xlsx file. This is great if you want to know what happened. It can also accompany a manuscript or paper to help others replicate analyses.</p>
<p>### Results Tab</p>
<p><code class="docutils literal notranslate"><span class="pre">`{image}</span> <span class="pre">_static/output_window.png</span>
<span class="pre">:alt:</span> <span class="pre">Results</span> <span class="pre">window</span>
<span class="pre">:width:</span> <span class="pre">400</span>
<span class="pre">`</span></code></p>
<p>This is where you can view results. You can select each voice file on the left and view each measurement result on the bottom frame. You can also view your spectrograms in the spectrogram window. You can change the size of any of these frames in order to see things better. Press {python}`Save Results` to save data. All data (results &amp; settings), manipulated voices, and spectrograms are saved automatically when this button is pressed. All you have to do is choose which folder to save into. Don’t worry about picking file names, Voice Lab will make those automatically for you.</p>
<p>#### Output formats</p>
<ul class="simple">
<li><p>All data files are saved as xlsx</p></li>
<li><p>All sound files are saved as wav</p></li>
<li><p>All image files are saved as png</p></li>
</ul>
<p># Documentation and API Reference</p>
<p>VoiceLab was not written with an API in mind but I am providing functionality anyways.  For now, it’s a bit rough.</p>
<p>This API is not yet complete. It is a work in progress. But, for now, there’s enough for you to run any node as long
as you can understand the code.  Reproducing Voicelab’s exact behaviour in the command line is a bit more difficult as
there is a state dictionary and and {python}`end()` method for nodes whose measures depend on other nodes (e.g Voice Tract-Length Estimates).</p>
<p>All nodes can be imported and run without the VoiceLab GUI if you program their execution in Python.</p>
<p>You’ll need to do some prep work to get your sounds in a form the nodes read. We are preparing for multiprocessing, and Parselmouth.Sound obejects don’t pickle
So, to avoid multiple disk reads and slow things down, we pass the values and sampling rate through the nodes.
That means to use this at the command line you need:</p>
<p>: {python}`args[‘file_path’]`, which is the file path, and
{python}`args[‘voice’]`, which is the {python}`parselmouth.Sound` object created by running
{python}`parselmouth.Sound(args[‘file_path’])`.
You also need {python}`signal`, and {python}`sampling_rate`, which you can get by doing:
{python}`signal = args[‘voice’].values` and {python}`sampling_rate  = args[‘voice’].sampling_frequency`.</p>
<p>You may also set additional parameters by creating an
instance of a node, and setting the dictionary {python}`args` to the appropriate values as specified
in each node. The output of each node is a dictionary of the results. If the node is a manipulation
node, it will return a {python}`parselmouth.Sound` object. If the node is a plot, it will return a matplotlib figure.
Otherwise, it will return mixed types of floats, integers, strings, and lists in the dictionary.</p>
<p>Validation analyses for automatic analysis settings and Energy can be found [here&lt;<a class="reference external" href="https://osf.io/3wr6k/files/">https://osf.io/3wr6k/files/</a>&gt;][here&lt;<a class="reference external" href="https://osf.io/3wr6k/files/">https://osf.io/3wr6k/files/</a>&gt;].</p>
<p>## Automated Settings</p>
<p>VoiceLab uses automated settings for pitch floor and ceiling, and also uses these to set the centre frequency parameter in the FormantPath formant analysis.</p>
<p>(id80)=</p>
<p>### Automated pitch floor and ceiling parameters</p>
<p>Praat suggests adjusting pitch settings based on [gender](<a class="reference external" href="http://www.fon.hum.uva.nl/praat/manual/Intro_4_2__Configuring_the_pitch_contour.html">http://www.fon.hum.uva.nl/praat/manual/Intro_4_2__Configuring_the_pitch_contour.html</a>) . It’s not gender per se that is important, but the pitch of voice. To mitigate this, VoiceLab first casts a wide net in  floor and ceiling settings to learn the range of probable fundamental frequencies is a voice. Then it remeasures the voice pitch using different settings for higher and lower pitched voices. VoiceLab by default uses employs {python}`very accurate`. VoiceLab returns {python}`minimum pitch`, {python}`maximum pitch`, {python}`mean pitch`, and {python}`standard deviation of pitch`. By default VoiceLab uses  autocorrelation for {ref}`Measuring Pitch&lt;Pitch&gt;`, and cross-correlation for {ref}`harmonicity&lt;HNR&gt;`, {ref}`Jitter&lt;Jitter&gt;`, and {ref}`Shimmer&lt;Shimmer&gt;`,</p>
<p>## Measurement Nodes</p>
<p>(id83)=</p>
<p>### Measure Pitch</p>
<p>This measures voice pitch or fundamental frequency. Users can measure pitch using any number of the following algorithms:
: - Praat Autocorrelation</p>
<blockquote>
<div><ul class="simple">
<li><p>Praat Cross Correlation</p></li>
<li><p>Yin (From Librosa)</p></li>
<li><p>Subharmonics (from Open Sauce)</p></li>
</ul>
</div></blockquote>
<p>By default it will measure all of these.</p>
<p>This uses Praat’s {python}`Sound: To Pitch (ac)…`, by default. You can also use the cross-correlation algorithm: {python}`Sound: To Pitch (cc)…`. For full details on these algorithms, see the [praat manual pitch page](<a class="reference external" href="http://www.fon.hum.uva.nl/praat/manual/Pitch.html">http://www.fon.hum.uva.nl/praat/manual/Pitch.html</a>).
{python}`Measure Pitch` returns the following measurements:</p>
<p>&gt; - A list of the pitch values
&gt; - Minimum Pitch
&gt; - Maximum Pitch
&gt; - Mean Pitch
&gt; - Standard Deviation of Pitch
&gt; - Pitch Floor (used to set window length)
&gt; - Pitch Ceiling (no candidates above this value will be considered)</p>
<p>We use the automated pitch floor and ceiling parameters described {ref}`here.&lt;floor-ceiling&gt;`</p>
<p>#### Measure Pitch Yin</p>
<p>This is the Yin implementation from Librosa.  This is now run out of the Measure Pitch Node.</p>
<p><a href="#id513"><span class="problematic" id="id514">``</span></a><a href="#id515"><span class="problematic" id="id516">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasurePitchNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id517"><span class="problematic" id="id518">``</span></a><a href="#id519"><span class="problematic" id="id520">`</span></a></p>
<p>#### Measure Subharmonics</p>
<p>This measures subharmonic pitch and subharmonic to harmonic ratio. Subharmonic to harmonic ratio and Subharmonic pitch are measures from Open Sauce (Yu et al., 2019), a Python port of Voice Sauce (Shue et al., 2011).  These measurements do not use any Praat or Parselmouth code.  As in (Shue et al., 2011) and (Yu et al., 2019), subharmonic raw values are padded with NaN values to 201 data points.</p>
<p><a href="#id521"><span class="problematic" id="id522">``</span></a><a href="#id523"><span class="problematic" id="id524">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureSHRPNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id525"><span class="problematic" id="id526">``</span></a><a href="#id527"><span class="problematic" id="id528">`</span></a></p>
<p>(id87)=</p>
<p>### Measure CPP (Cepstral Peak Prominence)</p>
<p>This measures Cepstral Peak Prominance in Praat. You can adjust interpolation, qeufrency upper and lower bounds, line type, and fit method.</p>
<p><a href="#id529"><span class="problematic" id="id530">``</span></a><a href="#id531"><span class="problematic" id="id532">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureCPPNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id533"><span class="problematic" id="id534">``</span></a><a href="#id535"><span class="problematic" id="id536">`</span></a></p>
<p>(id89)=</p>
<p>### Measure Duration</p>
<p>This measures the full duration of the sound file. There are no parameters to adjust.</p>
<p>(id91)=</p>
<p>### Measure Energy</p>
<p>This is my port of VoiceSauce’s Energy Algorithm.  It is different than the old RMS Energy algorithm in previous versions of VoiceLab. This code is not in OpenSauce.</p>
<p><a href="#id537"><span class="problematic" id="id538">``</span></a><a href="#id539"><span class="problematic" id="id540">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureEnergyNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id541"><span class="problematic" id="id542">``</span></a><a href="#id543"><span class="problematic" id="id544">`</span></a></p>
<p>(id93)=</p>
<p>### Measure Formants</p>
<p>This returns the mean of the first 4 formant frequencies of the voice using the {python}`To FormantPath` algorithm using
5.5 maximum number of formants and a variable centre frequency, set automatically or user-specified.  All other values
are Praat defaults for Formant Path.  Formant path picks the best formant ceiling value by fitting each prediction to a
polynomial curve, and choosing the best fit for each formant. The centre frequency is determined in the automatic
settings You can also use your own settings for {python}`To Formant Burg…` if you want to.</p>
<p><a href="#id545"><span class="problematic" id="id546">``</span></a><a href="#id547"><span class="problematic" id="id548">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureFormantNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id549"><span class="problematic" id="id550">``</span></a><a href="#id551"><span class="problematic" id="id552">`</span></a></p>
<p>### Measure Vocal Tract Length Estimates</p>
<p>This returns the following vocal tract length estimates:</p>
<p>#### Average Formant</p>
<p>This calculates the mean $frac {sum _{i=1}^{n} {f_i}}{n}$ of the first four formant frequencies for each sound.</p>
<p>Pisanski, K., &amp; Rendall, D. (2011). The prioritization of voice fundamental frequency or formants in listeners’ assessments of speaker size, masculinity, and attractiveness. The Journal of the Acoustical Society of America, 129(4), 2201-2212.</p>
<p>#### Principle Components Analysis</p>
<p>This returns the first factor from a Principle Components Analysis (PCA) of the 4 formants.</p>
<p>Babel, M., McGuire, G., &amp; King, J. (2014). Towards a more nuanced view of vocal attractiveness. PloS one, 9(2), e88616.</p>
<p>#### Geometric Mean</p>
<p>This calculates the geometric mean $left(prod _{i=1}^{n}f_{i}right)^{frac {1}{n}}$ of the first 4 formant frequencies for each sound.</p>
<p>Smith, D. R., &amp; Patterson, R. D. (2005). The interaction of glottal-pulse rate andvocal-tract length in judgements of speaker size, sex, and age.Journal of theAcoustical Society of America, 118, 3177e3186.</p>
<p>#### Formant Dispersion</p>
<p>$frac {sum _{i=2}^{n} {f_i - f_{i-1}}}{n}$</p>
<p>Fitch, W. T. (1997). Vocal-tract length and formant frequency dispersion correlate with body size in rhesus macaques.Journal of the Acoustical Society of America,102,1213e1222.</p>
<p>#### VTL</p>
<p>$frac {sum _{i=1}^{n} (2n-1) frac {f_i}{4c}}{n}$</p>
<p>Fitch, W. T. (1997). Vocal-tract length and formant frequency dispersion correlate with body size in rhesus macaques.Journal of the Acoustical Society of America,102,1213e1222.</p>
<p>Titze, I. R. (1994).Principles of voice production. Englewood Cliffs, NJ: Prentice Hall.</p>
<p>#### VTL Δf</p>
<p>$f_i$ = The slope of 0 intercept regression between $F_i = frac {(2i-1)}{2} Δf$ and the mean of each of the first 4 formant frequencies.</p>
<p>$VTL f_i = frac {sum _{i=1}^{n} (2n-1)(frac {c}{4f_i})}{n}$</p>
<p>$VTL Delta f = frac {c}{2Δf}$</p>
<p>Reby,D.,&amp;McComb,K.(2003).Anatomical constraints generate honesty: acoustic cues to age and weight in the roars of red deer stags. Animal Behaviour, 65,519e530.</p>
<p>(id102)=</p>
<p>#### Measure Formant Positions Node</p>
<p>This node measures formant position. This node is executed by MeasureVocalTractEstimatesNode.</p>
<p>Formant Position is set to only run on samples of 30 or greater because this measure is based on scaling the data. Without a large enough sample, this measurement could be suspicious.</p>
<p>The algorithm is as follows:
: - First, measure formants at each gottal pulse.</p>
<blockquote>
<div><ul>
<li><p>Second, scale each formant separately.</p></li>
<li><p>Third, find the mean of the scaled formants.</p>
<p>&gt; - $frac{1}{n} {sum _{i=1}^{n}{f_i}}$</p>
</li>
</ul>
</div></blockquote>
<p>This algorithm deviates from the original in that it checks the data for a normal distribution before applying the z-score. If it is not normally distributed, it uses Scikit Learn’s [Robust Scalar](<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html">https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html</a>)
The scalar method is recorded in the voicelab_settings.xlsx file.</p>
<p>Puts, D. A., Apicella, C. L., &amp; Cárdenas, R. A. (2011). Masculine voices signal men’s threat potential in forager and industrial societies. Proceedings of the Royal Society B: Biological Sciences, 279(1728), 601-609.</p>
<p><a href="#id553"><span class="problematic" id="id554">``</span></a><a href="#id555"><span class="problematic" id="id556">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureVocalTractEstimatesNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id557"><span class="problematic" id="id558">``</span></a><a href="#id559"><span class="problematic" id="id560">`</span></a></p>
<p><a href="#id561"><span class="problematic" id="id562">``</span></a><a href="#id563"><span class="problematic" id="id564">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureFormantPositionsNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id565"><span class="problematic" id="id566">``</span></a><a href="#id567"><span class="problematic" id="id568">`</span></a></p>
<p>(id104)=</p>
<p>### Measure Harmonicity</p>
<p>This measures mean harmonics-to-noise-ratio using automatic floor and ceiling settings described {ref}`here.&lt;floor-ceiling&gt;`  Full details of the algorithm can be found in the [Praat Manual Harmonicity Page&lt;<a class="reference external" href="http://www.fon.hum.uva.nl/praat/manual/Harmonicity.html">http://www.fon.hum.uva.nl/praat/manual/Harmonicity.html</a>&gt;][praat manual harmonicity page&lt;<a class="reference external" href="http://www.fon.hum.uva.nl/praat/manual/harmonicity.html">http://www.fon.hum.uva.nl/praat/manual/harmonicity.html</a>&gt;]. By default Voice Lab use {python}`To Harmonicity (cc)..`. You can select {python}`To Harmonicity (ac)` or change any other Praat parameters if you wish.</p>
<p><a href="#id569"><span class="problematic" id="id570">``</span></a><a href="#id571"><span class="problematic" id="id572">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureHarmonicityNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id573"><span class="problematic" id="id574">``</span></a><a href="#id575"><span class="problematic" id="id576">`</span></a></p>
<p>### Measure Intensity</p>
<p>This returns the mean of Praat’s  {python}`Sound: To Intensity…` function in dB. You can adjust the minimum pitch parameter. For more information, see Praat
s [Configuring the intensity contour Page](<a class="reference external" href="https://www.fon.hum.uva.nl/praat/manual/Intro_6_2__Configuring_the_intensity_contour.html">https://www.fon.hum.uva.nl/praat/manual/Intro_6_2__Configuring_the_intensity_contour.html</a>).</p>
<p><a href="#id577"><span class="problematic" id="id578">``</span></a><a href="#id579"><span class="problematic" id="id580">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureIntensityNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id581"><span class="problematic" id="id582">``</span></a><a href="#id583"><span class="problematic" id="id584">`</span></a></p>
<p>(id107)=</p>
<p>### Measure Jitter</p>
<p>This measures and returns values of all of [Praat’s jitter algorithms](<a class="reference external" href="http://www.fon.hum.uva.nl/praat/manual/Voice_2__Jitter.html">http://www.fon.hum.uva.nl/praat/manual/Voice_2__Jitter.html</a>). This can be a bit overwhelming or difficult to understand which measure to use and why, or can lead to multiple colinear comparisons. To address this, by default, Voice Lab returns a the first component from a principal components analysis of those jitter algorithms taken across all selected voices. The underlying reasoning here is that each of these algorithms measures something about how noisy the voice is due to perturbations in period length. The PCA finds what is common about all of these measures of noise, and gives you a score relative to your sample. With a large enough sample, the PCA score should be a more robust measure of jitter than any single measurement. Voice Lab uses use it’s {ref}`automated pitch floor and ceiling algorithm.&lt;floor-ceiling&gt;` to set analysis parameters.</p>
<p>Jitter Measures:</p>
<ul class="simple">
<li><p>Jitter (local)</p></li>
<li><p>Jitter (local, absolute)</p></li>
<li><p>Jitter (rap)</p></li>
<li><p>Jitter (ppq5)</p></li>
<li><p>Jitter (ddp)</p></li>
</ul>
<p><a href="#id585"><span class="problematic" id="id586">``</span></a><a href="#id587"><span class="problematic" id="id588">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureJitterNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id589"><span class="problematic" id="id590">``</span></a><a href="#id591"><span class="problematic" id="id592">`</span></a></p>
<p>(id109)=</p>
<p>### Measure Shimmer</p>
<p>This measures and returns values of all of [Praat’s shimmer algorithms](<a class="reference external" href="http://www.fon.hum.uva.nl/praat/manual/Voice_3__Shimmer.html">http://www.fon.hum.uva.nl/praat/manual/Voice_3__Shimmer.html</a>). This can be a bit overwhelming or difficult to understand which measure to use and why, or can lead to multiple colinear comparisons. To address this, by default, Voice Lab returns a the first component from a principal components analysis of those shimmer algorithms taken across all selected voices. The underlying reasoning here is that each of these algorithms measures something about how noisy the voice is due to perturbations in amplitude of periods. The PCA finds what is common about all of these measures of noise, and gives you a score relative to your sample. With a large enough sample, the PCA score should be a more robust measure of shimmer than any single measurement. Voice Lab uses use it’s {ref}`automated pitch floor and ceiling algorithm.&lt;floor-ceiling&gt;` to set analysis parameters.</p>
<p>Shimmer Measures:</p>
<ul class="simple">
<li><p>Shimmer (local)</p></li>
<li><p>Shimmer (local, dB)</p></li>
<li><p>Shimmer (apq3)</p></li>
<li><p>Shimmer (aqp5)</p></li>
<li><p>Shimmer (apq11)</p></li>
<li><p>Shimmer (ddp)</p></li>
</ul>
<p><a href="#id593"><span class="problematic" id="id594">``</span></a><a href="#id595"><span class="problematic" id="id596">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureShimmerNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id597"><span class="problematic" id="id598">``</span></a><a href="#id599"><span class="problematic" id="id600">`</span></a></p>
<p>### Measure LTAS</p>
<p>This measures several items from the Long-Term Average Spectrum using Praat’s default settings.</p>
<ul class="simple">
<li><p>mean (dB)</p></li>
<li><p>slope (dB)</p></li>
<li><p>local peak height (dB)</p></li>
<li><p>standard deviation (dB)</p></li>
<li><p>spectral tilt slope (dB/Hz)</p></li>
<li><p>spectral tilt intercept (dB)</p></li>
</ul>
<p>You can adjust:
- Pitch correction
- Bandwidth
- Max Frequency
- Shortest and longest periods
- Maximum period factor</p>
<p><a href="#id601"><span class="problematic" id="id602">``</span></a><a href="#id603"><span class="problematic" id="id604">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureLTASNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id605"><span class="problematic" id="id606">``</span></a><a href="#id607"><span class="problematic" id="id608">`</span></a></p>
<p>### Measure MFCC</p>
<p>This node measures the first 24 Mel Cepstral Coeffecients of the sound.  There are no options to set. If you want fewer coeffecients, you can delete the one’s you don’t want. If you need the same number of values for each sound for Machine Learning, make sure the sounds are the same length before running the analysis.</p>
<p><a href="#id609"><span class="problematic" id="id610">``</span></a><a href="#id611"><span class="problematic" id="id612">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureMFCCNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id613"><span class="problematic" id="id614">``</span></a><a href="#id615"><span class="problematic" id="id616">`</span></a></p>
<p>### Measure Spectral Shape</p>
<p>This measures spectral:
- Centre of Gravity
- Standard Deviation
- Kurtosis
- Band Energy Difference
- Band Density Difference</p>
<p><a href="#id617"><span class="problematic" id="id618">``</span></a><a href="#id619"><span class="problematic" id="id620">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureSpectralShapeNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id621"><span class="problematic" id="id622">``</span></a><a href="#id623"><span class="problematic" id="id624">`</span></a></p>
<p>### Measure Spectral Tilt</p>
<p>This measures spectral tilt by returning the slope of a regression between freqeuncy and amplitude of each sound. This is from a script written by Michael J. Owren, with sorting errors corrected. This is not the same equation in Voice Sauce.</p>
<p>Owren, M.J. GSU Praat Tools: Scripts for modifying and analyzing sounds using Praat acoustics software. Behavior Research Methods (2008) 40:  822–829. &lt;<a class="reference external" href="https://doi.org/10.3758/BRM.40.3.822">https://doi.org/10.3758/BRM.40.3.822</a>&gt;</p>
<p><a href="#id625"><span class="problematic" id="id626">``</span></a><a href="#id627"><span class="problematic" id="id628">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureSpectralTiltNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id629"><span class="problematic" id="id630">``</span></a><a href="#id631"><span class="problematic" id="id632">`</span></a></p>
<p>### Measure Speech Rate</p>
<p>This function is an implementation of the Praat script published here:
De Jong, N.H. &amp; Wempe, T. (2009). Praat script to detect syllable nuclei and measure speech rate automatically. Behavior research methods, 41 (2), 385 - 390.</p>
<p>Voice Lab used version 2 of the script, available [here](<a class="reference external" href="https://sites.google.com/site/speechrate/Home/praat-script-syllable-nuclei-v2">https://sites.google.com/site/speechrate/Home/praat-script-syllable-nuclei-v2</a>).</p>
<p>This returns:
: - Number of Syllables</p>
<blockquote>
<div><ul class="simple">
<li><p>Number of Pauses</p></li>
<li><p>Duration(s)</p></li>
<li><p>Phonation Time(s)</p></li>
<li><p>Speech Rate (Number of Syllables / Duration)</p></li>
<li><p>Articulation Rate (Number of Syllables / Phonation Time)</p></li>
<li><p>Average Syllable Duration (Speaking Time / Number of Syllables)</p></li>
</ul>
</div></blockquote>
<p>You can adjust:
- silence threshold {python}`mindb`</p>
<ul class="simple">
<li><p>mimimum dip between peaks (dB) {python}`mindip`. This should be between 2-4. Try 4 for clean and filtered sounds, and lower numbers for noisier sounds.</p></li>
<li><p>minimum pause length {python}`minpause`</p></li>
</ul>
<p>This command really only words on sounds with a few syllables, since Voice Lab is measuring how fast someone speaks. For monosyllabic sounds, use the {ref}`Measure Duration function.&lt;Duration&gt;`</p>
<p><a href="#id633"><span class="problematic" id="id634">``</span></a><a href="#id635"><span class="problematic" id="id636">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.MeasureSpeechRateNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id637"><span class="problematic" id="id638">``</span></a><a href="#id639"><span class="problematic" id="id640">`</span></a></p>
<p>## Manipulation Nodes</p>
<p>### Lower Pitch</p>
<p>This lowers pitch using the PSOLA method. By default, this lowers  by 0.5 ERBs (Equivalent Rectangular Bandwidths) which is about 20 Hz at a 120 Hz pitch centre and about -/+ 25 Hz at a 240 Hz pitch centre. By default VoiceLab also normalizes intensity to 70 dB RMS, but you can turn this off by deselecting the box in the Settings tab.</p>
<p><a href="#id641"><span class="problematic" id="id642">``</span></a><a href="#id643"><span class="problematic" id="id644">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.ManipulatePitchLowerNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id645"><span class="problematic" id="id646">``</span></a><a href="#id647"><span class="problematic" id="id648">`</span></a></p>
<p>### Raise Pitch</p>
<p>This raises pitch using the PSOLA method. By default, this lowers  by 0.5 ERBs (Equivalent Rectangular Bandwidths) which is about 20 Hz at a 120 Hz pitch centre and about -/+ 25 Hz at a 240 Hz pitch centre. By default VoiceLab also normalizes intensity to 70 dB RMS, but you can turn this off by deselecting the box in the Settings tab.</p>
<p><a href="#id649"><span class="problematic" id="id650">``</span></a><a href="#id651"><span class="problematic" id="id652">`</span></a>{eval-rst}
.. automodule:: voicelab.src.voicelab.src.Voicelab.toolkits.Voicelab.ManipulatePitchHigherNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id653"><span class="problematic" id="id654">``</span></a><a href="#id655"><span class="problematic" id="id656">`</span></a></p>
<p>### Lower Formants</p>
<p>This lowers formants using Praat’s Change Gender Function. By default, Formants are lowered by 15%. This manipulation resamples a sound by the Formant scaling factor (which can be altered in the Settings tab). Then, the sampling rate is overriden to the sound’s original sampling rate. Then PSOLA is employed to stretch time and pitch back (separately) into their original values. By default VoiceLab also normalizes intensity to 70 dB RMS, but you can turn this off by deselecting the box in the Settings tab.</p>
<p><a href="#id657"><span class="problematic" id="id658">``</span></a><a href="#id659"><span class="problematic" id="id660">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.ManipulateLowerFormantsNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id661"><span class="problematic" id="id662">``</span></a><a href="#id663"><span class="problematic" id="id664">`</span></a></p>
<p>### Raise Formants</p>
<p>This raises formants using Praat’s Change Gender Function. By default, Formants are raised by 15%. This manipulation resamples a sound by the Formant scaling factor (which can be altered in the Settings tab). Then, the sampling rate is overriden to the sound’s original sampling rate. Then PSOLA is employed to stretch time and pitch back (separately) into their original values. By default VoiceLab also normalizes intensity to 70 dB RMS, but you can turn this off by deselecting the box in the Settings tab.</p>
<p><a href="#id665"><span class="problematic" id="id666">``</span></a><a href="#id667"><span class="problematic" id="id668">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.ManipulateRaiseFormantsNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id669"><span class="problematic" id="id670">``</span></a><a href="#id671"><span class="problematic" id="id672">`</span></a></p>
<p>### Lower Pitch and Formants</p>
<p>This manipulation lowers both pitch and formants in the same direction by the same or independent amounts. This uses the algorithm described in Manipulate Formants, but allows the user to scale or shift pitch to a designated degree. By default, pitch is also lowered by 15%. By default VoiceLab also normalizes intensity to 70 dB RMS, but you can turn this off by deselecting the box in the Settings tab.</p>
<p><a href="#id673"><span class="problematic" id="id674">``</span></a><a href="#id675"><span class="problematic" id="id676">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.ManipulateLowerPitchAndFormantsNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id677"><span class="problematic" id="id678">``</span></a><a href="#id679"><span class="problematic" id="id680">`</span></a></p>
<p>### Raise Pitch and Formants</p>
<p>This manipulation raises both pitch and formants in the same direction by the same or independent amounts. This uses the algorithm described in Manipulate Formants, but allows the user to scale or shift pitch to a designated degree. By default, pitch is also raised by 15%. By default VoiceLab also normalizes intensity to 70 dB RMS, but you can turn this off by deselecting the box in the Settings tab.</p>
<p><a href="#id681"><span class="problematic" id="id682">``</span></a><a href="#id683"><span class="problematic" id="id684">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.ManipulateRaisePitchAndFormantsNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id685"><span class="problematic" id="id686">``</span></a><a href="#id687"><span class="problematic" id="id688">`</span></a></p>
<p>### Reverse Sounds</p>
<p>This reverses the selected sounds. Use this if you want to play sounds backwards. Try a Led Zepplin or Beatles song.</p>
<p><a href="#id689"><span class="problematic" id="id690">``</span></a><a href="#id691"><span class="problematic" id="id692">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.ReverseSoundsNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id693"><span class="problematic" id="id694">``</span></a><a href="#id695"><span class="problematic" id="id696">`</span></a></p>
<p>### Resample Sounds</p>
<p>This is a quick and easy way to batch process resampling sounds. 44.1kHz is the default. Change this value in the Settings tab.</p>
<p><a href="#id697"><span class="problematic" id="id698">``</span></a><a href="#id699"><span class="problematic" id="id700">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.ResampleSoundsNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id701"><span class="problematic" id="id702">``</span></a><a href="#id703"><span class="problematic" id="id704">`</span></a></p>
<p>### Rotate Spectrum</p>
<p>This resamples the sound, rotates the selected sounds by 180 degrees and reverses it so it’s just the inverted frequency spectrum.
This script is from Chris Darwin and reproduced here with permission: [The original script can be found here](<a class="reference external" href="http://www.lifesci.sussex.ac.uk/home/Chris_Darwin/Praatscripts/Spectral%20Rotation">http://www.lifesci.sussex.ac.uk/home/Chris_Darwin/Praatscripts/Spectral%20Rotation</a>).</p>
<p>A similar technique was used here: Bédard, C., &amp; Belin, P. (2004). A “voice inversion effect?”. Brain and cognition, 55(2), 247-249.</p>
<p><a href="#id705"><span class="problematic" id="id706">``</span></a><a href="#id707"><span class="problematic" id="id708">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.RotateSpectrumNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id709"><span class="problematic" id="id710">``</span></a><a href="#id711"><span class="problematic" id="id712">`</span></a></p>
<p>### Scale Intensity</p>
<p>This scales intensity with Peak or RMS. Use this if you want your sounds to all be at an equivalent amplitude. By default intensity is normalized to 70 dB using RMS. If you use peak, it is scaled between -1 and 1, so pick a number between -1 and 1 to normalize to peak.</p>
<p><a href="#id713"><span class="problematic" id="id714">``</span></a><a href="#id715"><span class="problematic" id="id716">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.ScaleIntensityNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id717"><span class="problematic" id="id718">``</span></a><a href="#id719"><span class="problematic" id="id720">`</span></a></p>
<p>### Truncate Sounds</p>
<p>This trims and/or truncates sounds. You can trim a % of time off the ends of the sound, or voicelab can automatically detect silences at the beginning and end of the sound, and clip those out also.
If you have trouble with trimming silences, try adjusting the silence ratio in the Settings tab.</p>
<p><a href="#id721"><span class="problematic" id="id722">``</span></a><a href="#id723"><span class="problematic" id="id724">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.ManipulateTruncateSoundsNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id725"><span class="problematic" id="id726">``</span></a><a href="#id727"><span class="problematic" id="id728">`</span></a></p>
<p>## Visualization Nodes</p>
<p>### Spectrograms</p>
<p><code class="docutils literal notranslate"><span class="pre">`{image}</span> <span class="pre">_static/spectrogram.png</span>
<span class="pre">:alt:</span> <span class="pre">Spectrogram</span>
<span class="pre">:width:</span> <span class="pre">400</span>
<span class="pre">`</span></code></p>
<p>VoiceLab creates full colour spectrograms. By default we use a wide-band window. You can adjust the window length. For example, for a narrow-band spectrogram, you can try 0.005 as a window length. You can also select a different colour palate. You can also overlay pitch, the first four formant frequencies, and intensity measures on the spectrogram.</p>
<p><a href="#id729"><span class="problematic" id="id730">``</span></a><a href="#id731"><span class="problematic" id="id732">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.VisualizeVoiceNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id733"><span class="problematic" id="id734">``</span></a><a href="#id735"><span class="problematic" id="id736">`</span></a></p>
<p>### Power Spectra</p>
<p><code class="docutils literal notranslate"><span class="pre">`{image}</span> <span class="pre">_static/power_spectrum.png</span>
<span class="pre">:alt:</span> <span class="pre">Power</span> <span class="pre">spectrum</span>
<span class="pre">:width:</span> <span class="pre">400</span>
<span class="pre">`</span></code></p>
<p>VoiceLab creates power spectra of sounds and overlays an LPC curve over the top.</p>
<p><a href="#id737"><span class="problematic" id="id738">``</span></a><a href="#id739"><span class="problematic" id="id740">`</span></a>{eval-rst}
.. automodule:: voicelab.src.Voicelab.toolkits.Voicelab.VisualizeSpectrumNode</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">members<span class="colon">:</span></dt>
<dd class="field-odd"><p></p></dd>
</dl>
</div></blockquote>
<p><a href="#id741"><span class="problematic" id="id742">``</span></a><a href="#id743"><span class="problematic" id="id744">`</span></a></p>
<p>(codeexample)=</p>
<p>### Code Example</p>
<p>Running Voicelab from the command line was never intended, but you can hack your way through.
This is a code example from the tests. It shows how to run Voicelab from the command line.
This is not a supported way to run Voicelab, but it works.
This will work if you clone the github repo and run it from the command line, but not if you install it from
PyPi or Binary.
You can adapt this for any node.  See source code for the node you want to run for more details.
I have the directory structure set up below.  You might need to fiddle with it.
The <cite>prepare_node()</cite> function sets up the node with the sound file the way it likes it and returns the node.
The <cite>process()</cite> method runs the node.</p>
<p><a href="#id745"><span class="problematic" id="id746">``</span></a><a href="#id747"><span class="problematic" id="id748">`</span></a>Python import sys import os import parselmouth import numpy as np import pytest
# Set up paths
TEST_DIR = os.path.dirname(os.path.realpath(__file__))
VOICELAB_DIR = os.path.dirname(TEST_DIR)
AUDIO_DIR = os.path.join(VOICELAB_DIR, ‘tests/assets/audio’)</p>
<p># in order for the relative imports in the files we are testing to run correctly,
# we need to add these directories to the path
sys.path.insert(0, ‘’.join([VOICELAB_DIR, “/src/Voicelab/toolkits/Voicelab”]))
sys.path.insert(0, ‘’.join([VOICELAB_DIR, “/src”]))
import ReverseSoundsNode  # Pycharm doesn’t like this, but it works
<a href="#id749"><span class="problematic" id="id750">``</span></a><a href="#id751"><span class="problematic" id="id752">`</span></a></p>
<p><a href="#id753"><span class="problematic" id="id754">``</span></a><a href="#id755"><span class="problematic" id="id756">`</span></a>Python
# Arrange
def get_test_files():</p>
<blockquote>
<div><p>number_of_test_files = len(os.listdir(AUDIO_DIR)) - 1  # -1 because the first file is a broken sound
test_files = sorted(os.listdir(AUDIO_DIR))[1:]
return number_of_test_files, test_files</p>
</div></blockquote>
<p><a href="#id757"><span class="problematic" id="id758">``</span></a><a href="#id759"><span class="problematic" id="id760">`</span></a></p>
<p><a href="#id761"><span class="problematic" id="id762">``</span></a><a href="#id763"><span class="problematic" id="id764">`</span></a>Python
# Arrange
def prepare_node(test_file):</p>
<blockquote>
<div><p>file_path = os.path.join(AUDIO_DIR, test_file)
node = ReverseSoundsNode.ReverseSoundsNode()
node.args[‘file_path’] = file_path
# Load the sound and setup the node
try:</p>
<blockquote>
<div><p>sound: parselmouth.Sound = parselmouth.Sound(file_path)
signal = sound.values
sampling_rate = sound.sampling_frequency</p>
</div></blockquote>
<dl class="simple">
<dt>except:</dt><dd><p>signal = None
sampling_rate = None</p>
</dd>
</dl>
<p>node.voice = (signal, sampling_rate)
node.args[‘voice’] = (signal, sampling_rate)
print((f”{file_path=}..{sampling_rate=}”))
return node</p>
</div></blockquote>
<p><a href="#id765"><span class="problematic" id="id766">``</span></a><a href="#id767"><span class="problematic" id="id768">`</span></a></p>
<p><a href="#id769"><span class="problematic" id="id770">``</span></a><a href="#id771"><span class="problematic" id="id772">`</span></a>Python
# Arrange
def get_reversed_test_sound(test_file):</p>
<blockquote>
<div><p>file_path = os.path.join(AUDIO_DIR, test_file)
validation_sound = parselmouth.Sound(file_path)
validation_sound.reverse()
return validation_sound.values</p>
</div></blockquote>
<p><a href="#id773"><span class="problematic" id="id774">``</span></a><a href="#id775"><span class="problematic" id="id776">`</span></a></p>
<p><a href="#id777"><span class="problematic" id="id778">``</span></a><a href="#id779"><span class="problematic" id="id780">`</span></a>Python
# Arrange
def get_number_of_test_files():</p>
<blockquote>
<div><p>number_of_test_files, _ = get_test_files()
return number_of_test_files</p>
</div></blockquote>
<p><a href="#id781"><span class="problematic" id="id782">``</span></a><a href="#id783"><span class="problematic" id="id784">`</span></a></p>
<p><a href="#id785"><span class="problematic" id="id786">``</span></a><a href="#id787"><span class="problematic" id="id788">`</span></a>Python
# Arrange
def generate_numpy_arrays(execution_number):</p>
<blockquote>
<div><p>number_of_test_files, test_files = get_test_files()
filename = test_files[execution_number]
node = prepare_node(filename)
# Run the node
results = node.process()
print(results)
# Validate the results
validation_sound = get_reversed_test_sound(filename)
test_sound = results[‘voice’].values
return test_sound, validation_sound</p>
</div></blockquote>
<p># Act
&#64;pytest.mark.parametrize(‘execution_number’, range(len(os.listdir(AUDIO_DIR)) - 1))
def test_ReverseSoundsNode(execution_number):</p>
<blockquote>
<div><p>test_sound, validation_sound = generate_numpy_arrays(execution_number)
assert np.array_equal(test_sound, validation_sound)</p>
</div></blockquote>
<p><a href="#id789"><span class="problematic" id="id790">``</span></a><a href="#id791"><span class="problematic" id="id792">`</span></a></p>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2023, David R Feinberg.

    </p>
  </div> 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>